[10/27 18:13:13] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 18:13:15] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[10/27 18:13:15] detectron2 INFO: Command line arguments: Namespace(annotdir='default', config_file='/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/results/SOLOv2_minicoco_run2/model_0029999.pth'], resume=False)
[10/27 18:13:15] detectron2 INFO: Contents of args.config_file=/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml:
_BASE_: "Base-SOLOv2.yaml"
MODEL:
  WEIGHTS: '/root/data/pretrained_models/R-50.pkl'
  BACKBONE:
    FREEZE_AT: 5
  RESNETS:
    DEPTH: 50
  SOLOV2:
    NUM_CLASSES: 3
SOLVER:
  STEPS: (60000, 80000)
  MAX_ITER: 270000
  IMS_PER_BATCH: 4
  CHECKPOINT_PERIOD: 2500
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 640
  MASK_FORMAT: "bitmask"
DATASETS:
  TRAIN: ("minicoco_train",)
  TEST: ("minicoco_val",)
[10/27 18:13:15] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('minicoco_val',)
  TRAIN: ('minicoco_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: True
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: True
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    ANTI_ALIAS: False
    FREEZE_AT: 5
    NAME: build_resnet_fpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES: ['p3', 'p4', 'p5']
    LOSS_ON: False
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES: ['p2', 'p3', 'p4']
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION: (8, 32)
    POOLER_SCALES: (0.25, 0.125, 0.0625)
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES: (0.25,)
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: False
  BiFPN:
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CFS:
    ATTN_EMBED_SIZE: 64
    BACKBONE_MLP_HIDDEN_SIZE: 64
    BOTTLENECK_SIZE: 0
    DROPOUT: 0.0
    MASK_TO_FEATURE: lineintegral
    NORM: ln
    NUM_BACKBONE_LAYERS: 2
    NUM_HEADS: [8]
    SOLO_GT_SCHEME: weight
    THETA_SAMPLES: 16
    TRAIN_SOLO: True
    TRAIN_TRANSFORMER: False
    TRANSFORMER_ADVERSARIAL_LOSS: False
    TRANSFORMER_AUX_LOSS: False
    TRANSFORMER_GT_SCHEME: weight
    USE_ATTN_BOTTLENECK: [0]
  CONDINST:
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES: ['p3', 'p4', 'p5']
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: False
    MASK_HEAD:
      CHANNELS: 8
      DISABLE_REL_COORDS: False
      NUM_LAYERS: 3
      USE_FP16: False
    MASK_OUT_STRIDE: 4
    MAX_PROPOSALS: -1
  DEVICE: cuda
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  FCOS:
    CENTER_SAMPLE: True
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    USE_DEFORMABLE: False
    USE_RELU: True
    USE_SCALE: True
    YIELD_PROPOSAL: False
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  MEInst:
    AGNOSTIC: True
    CENTER_SAMPLE: True
    DIM_MASK: 60
    FLAG_PARAMETERS: False
    FPN_STRIDES: [8, 16, 32, 64, 128]
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    LAST_DEFORMABLE: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: False
    MASK_LOSS_TYPE: mse
    MASK_ON: True
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: True
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: False
    USE_GCN_IN_MASK: False
    USE_RELU: True
    USE_SCALE: True
    WHITEN: True
  META_ARCHITECTURE: SOLOv2
  MOBILENET: False
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SOLOV2:
    DEL_OLD_MASKS: False
    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]
    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))
    INSTANCE_CHANNELS: 512
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_MODE: iou
    KERN_TO_CATE: False
    KERN_TO_CATE_NUM_LAYERS: 0
    LOSS:
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: True
      FOCAL_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_CONTRAST: False
    MASK_CONTRAST_DIMS: 128
    MASK_CONTRAST_WEIGHT: 1.0
    MASK_HEAD_LEAKYRELU_ALPHA: 0.0
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    MASK_THR: 0.5
    MAX_PER_IMG: 100
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NORM: GN
    NUM_CLASSES: 3
    NUM_GRIDS: [40, 36, 24, 16, 12]
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    ONE_CLS_PER_LOC: False
    PRIOR_PROB: 0.01
    SCORE_THR: 0.1
    SEM_SEG: False
    SEM_SEG_NEG_TRAIN: False
    SEM_SEG_NUM_LAYERS: 2
    SEM_SEG_WEIGHT: 1.0
    SIGMA: 0.2
    TRAIN_BG_MASKS: False
    TRAIN_BG_MODE: dice
    TRAIN_BG_WEIGHT: 1.0
    TRAIN_VEC_FIELDS: False
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: True
    USE_DCN_IN_INSTANCE: False
    VEC_FIELDS_WEIGHT: 1.0
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  WEIGHTS: /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 2500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_IMAGE_NUM: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[10/27 18:13:15] detectron2 INFO: Full config saved to ./output/config.yaml
[10/27 18:13:15] d2.utils.env INFO: Using a generated random seed 15306212
[10/27 18:13:15] adet.modeling.solov2.solov2 WARNING: Not deleting old masks: this is default behavior in SOLO code.
[10/27 18:13:15] adet.modeling.solov2.solov2 WARNING: Ignore the above message if you're using SOLO as a sub-module.
[10/27 18:13:17] d2.engine.defaults INFO: Model:
SOLOv2(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (ins_head): SOLOv2InsHead(
    (cate_tower): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (kernel_tower): Sequential(
      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (cate_pred): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (mask_head): SOLOv2MaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
      )
      (1): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv0): Sequential(
          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (k2c_layers): ModuleList()
  (vec_fields_head): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
)
[10/27 18:13:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth ...
[10/27 18:13:17] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mvec_fields_head.{bias, weight}[0m
[10/27 18:13:18] d2.data.datasets.coco INFO: Loaded 326 images in COCO format from /root/data/miniCOCO/instances_val2021.json
[10/27 18:13:18] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  vehicles  | 104          |   people   | 98           |  animals   | 179          |
|            |              |            |              |            |              |
|   total    | 381          |            |              |            |              |[0m
[10/27 18:13:18] d2.data.common INFO: Serializing 326 elements to byte tensors and concatenating them all ...
[10/27 18:13:18] d2.data.common INFO: Serialized dataset takes 1.86 MiB
[10/27 18:13:18] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[10/27 18:13:18] d2.evaluation.evaluator INFO: Start inference on 326 images
[10/27 18:14:45] d2.evaluation.evaluator INFO: Inference done 1/326. 86.4630 s / img. ETA=7:54:30
[10/27 18:14:50] d2.evaluation.evaluator INFO: Inference done 109/326. 0.0401 s / img. ETA=0:00:09
[10/27 18:14:55] d2.evaluation.evaluator INFO: Inference done 216/326. 0.0404 s / img. ETA=0:00:05
[10/27 18:15:00] d2.evaluation.evaluator INFO: Inference done 325/326. 0.0403 s / img. ETA=0:00:00
[10/27 18:15:01] d2.evaluation.evaluator INFO: Total inference time: 0:00:15.635823 (0.048710 s / img per device, on 1 devices)
[10/27 18:15:01] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:12 (0.040266 s / img per device, on 1 devices)
[10/27 18:15:01] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[10/27 18:15:01] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[10/27 18:15:01] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[10/27 18:15:01] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.275 | 72.037 | 42.332 | 16.411 | 36.856 | 43.029 |
[10/27 18:15:01] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| vehicles   | 42.862 | people     | 33.861 | animals    | 47.103 |
[10/27 18:15:02] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.639 | 79.619 | 40.524 | 32.827 | 38.488 | 52.644 |
[10/27 18:15:02] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| vehicles   | 39.933 | people     | 36.149 | animals    | 54.834 |
[10/27 18:15:02] d2.evaluation.f1score_evaluator INFO: Preparing results for COCO format ...
[10/27 18:15:02] d2.evaluation.f1score_evaluator INFO: Evaluating predictions ...
[10/27 18:15:03] d2.evaluation.f1score_evaluator INFO: Evaluation results for F1-score: 
|  F1-all  |  F1-0.5  |  F1-0.75  |  F1-small  |  F1-medium  |  F1-large  |
|:--------:|:--------:|:---------:|:----------:|:-----------:|:----------:|
|  0.101   |  0.159   |   0.109   |   0.001    |    0.048    |   0.064    |
[10/27 18:15:03] d2.engine.defaults INFO: Evaluation results for minicoco_val in csv format:
[10/27 18:15:03] d2.evaluation.testing INFO: copypaste: Task: bbox
[10/27 18:15:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[10/27 18:15:03] d2.evaluation.testing INFO: copypaste: 41.2753,72.0365,42.3321,16.4109,36.8557,43.0286
[10/27 18:15:03] d2.evaluation.testing INFO: copypaste: Task: segm
[10/27 18:15:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[10/27 18:15:03] d2.evaluation.testing INFO: copypaste: 43.6388,79.6193,40.5242,32.8267,38.4882,52.6438
[10/27 18:15:03] d2.evaluation.testing INFO: copypaste: Task: f1-segm
[10/27 18:15:03] d2.evaluation.testing INFO: copypaste: 
[10/27 18:15:03] d2.evaluation.testing INFO: copypaste: 
[10/27 18:27:36] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 18:27:37] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[10/27 18:27:37] detectron2 INFO: Command line arguments: Namespace(annotdir='default', config_file='/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/results/SOLOv2_minicoco_run2/model_0029999.pth'], resume=False)
[10/27 18:27:37] detectron2 INFO: Contents of args.config_file=/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml:
_BASE_: "Base-SOLOv2.yaml"
MODEL:
  WEIGHTS: '/root/data/pretrained_models/R-50.pkl'
  BACKBONE:
    FREEZE_AT: 5
  RESNETS:
    DEPTH: 50
  SOLOV2:
    NUM_CLASSES: 3
SOLVER:
  STEPS: (60000, 80000)
  MAX_ITER: 270000
  IMS_PER_BATCH: 4
  CHECKPOINT_PERIOD: 2500
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 640
  MASK_FORMAT: "bitmask"
DATASETS:
  TRAIN: ("minicoco_train",)
  TEST: ("minicoco_val",)
[10/27 18:27:37] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('minicoco_val',)
  TRAIN: ('minicoco_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: True
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: True
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    ANTI_ALIAS: False
    FREEZE_AT: 5
    NAME: build_resnet_fpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES: ['p3', 'p4', 'p5']
    LOSS_ON: False
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES: ['p2', 'p3', 'p4']
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION: (8, 32)
    POOLER_SCALES: (0.25, 0.125, 0.0625)
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES: (0.25,)
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: False
  BiFPN:
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CFS:
    ATTN_EMBED_SIZE: 64
    BACKBONE_MLP_HIDDEN_SIZE: 64
    BOTTLENECK_SIZE: 0
    DROPOUT: 0.0
    MASK_TO_FEATURE: lineintegral
    NORM: ln
    NUM_BACKBONE_LAYERS: 2
    NUM_HEADS: [8]
    SOLO_GT_SCHEME: weight
    THETA_SAMPLES: 16
    TRAIN_SOLO: True
    TRAIN_TRANSFORMER: False
    TRANSFORMER_ADVERSARIAL_LOSS: False
    TRANSFORMER_AUX_LOSS: False
    TRANSFORMER_GT_SCHEME: weight
    USE_ATTN_BOTTLENECK: [0]
  CONDINST:
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES: ['p3', 'p4', 'p5']
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: False
    MASK_HEAD:
      CHANNELS: 8
      DISABLE_REL_COORDS: False
      NUM_LAYERS: 3
      USE_FP16: False
    MASK_OUT_STRIDE: 4
    MAX_PROPOSALS: -1
  DEVICE: cuda
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  FCOS:
    CENTER_SAMPLE: True
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    USE_DEFORMABLE: False
    USE_RELU: True
    USE_SCALE: True
    YIELD_PROPOSAL: False
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  MEInst:
    AGNOSTIC: True
    CENTER_SAMPLE: True
    DIM_MASK: 60
    FLAG_PARAMETERS: False
    FPN_STRIDES: [8, 16, 32, 64, 128]
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    LAST_DEFORMABLE: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: False
    MASK_LOSS_TYPE: mse
    MASK_ON: True
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: True
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: False
    USE_GCN_IN_MASK: False
    USE_RELU: True
    USE_SCALE: True
    WHITEN: True
  META_ARCHITECTURE: SOLOv2
  MOBILENET: False
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SOLOV2:
    DEL_OLD_MASKS: False
    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]
    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))
    INSTANCE_CHANNELS: 512
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_MODE: iou
    KERN_TO_CATE: False
    KERN_TO_CATE_NUM_LAYERS: 0
    LOSS:
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: True
      FOCAL_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_CONTRAST: False
    MASK_CONTRAST_DIMS: 128
    MASK_CONTRAST_WEIGHT: 1.0
    MASK_HEAD_LEAKYRELU_ALPHA: 0.0
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    MASK_THR: 0.5
    MAX_PER_IMG: 100
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NORM: GN
    NUM_CLASSES: 3
    NUM_GRIDS: [40, 36, 24, 16, 12]
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    ONE_CLS_PER_LOC: False
    PRIOR_PROB: 0.01
    SCORE_THR: 0.1
    SEM_SEG: False
    SEM_SEG_NEG_TRAIN: False
    SEM_SEG_NUM_LAYERS: 2
    SEM_SEG_WEIGHT: 1.0
    SIGMA: 0.2
    TRAIN_BG_MASKS: False
    TRAIN_BG_MODE: dice
    TRAIN_BG_WEIGHT: 1.0
    TRAIN_VEC_FIELDS: False
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: True
    USE_DCN_IN_INSTANCE: False
    VEC_FIELDS_WEIGHT: 1.0
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  WEIGHTS: /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 2500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_IMAGE_NUM: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[10/27 18:27:38] detectron2 INFO: Full config saved to ./output/config.yaml
[10/27 18:27:38] d2.utils.env INFO: Using a generated random seed 38184573
[10/27 18:27:38] adet.modeling.solov2.solov2 WARNING: Not deleting old masks: this is default behavior in SOLO code.
[10/27 18:27:38] adet.modeling.solov2.solov2 WARNING: Ignore the above message if you're using SOLO as a sub-module.
[10/27 18:27:40] d2.engine.defaults INFO: Model:
SOLOv2(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (ins_head): SOLOv2InsHead(
    (cate_tower): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (kernel_tower): Sequential(
      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (cate_pred): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (mask_head): SOLOv2MaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
      )
      (1): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv0): Sequential(
          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (k2c_layers): ModuleList()
  (vec_fields_head): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
)
[10/27 18:27:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth ...
[10/27 18:27:40] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mvec_fields_head.{bias, weight}[0m
[10/27 18:27:40] d2.data.datasets.coco INFO: Loaded 326 images in COCO format from /root/data/miniCOCO/instances_val2021.json
[10/27 18:27:40] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  vehicles  | 104          |   people   | 98           |  animals   | 179          |
|            |              |            |              |            |              |
|   total    | 381          |            |              |            |              |[0m
[10/27 18:27:40] d2.data.common INFO: Serializing 326 elements to byte tensors and concatenating them all ...
[10/27 18:27:40] d2.data.common INFO: Serialized dataset takes 1.86 MiB
[10/27 18:27:40] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[10/27 18:27:40] d2.evaluation.evaluator INFO: Start inference on 326 images
[10/27 18:27:46] d2.evaluation.evaluator INFO: Inference done 1/326. 5.2651 s / img. ETA=0:32:54
[10/27 18:27:51] d2.evaluation.evaluator INFO: Inference done 109/326. 0.0399 s / img. ETA=0:00:09
[10/27 18:27:56] d2.evaluation.evaluator INFO: Inference done 218/326. 0.0400 s / img. ETA=0:00:04
[10/27 18:28:01] d2.evaluation.evaluator INFO: Inference done 325/326. 0.0403 s / img. ETA=0:00:00
[10/27 18:28:02] d2.evaluation.evaluator INFO: Total inference time: 0:00:15.711288 (0.048945 s / img per device, on 1 devices)
[10/27 18:28:02] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:12 (0.040282 s / img per device, on 1 devices)
[10/27 18:28:03] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[10/27 18:28:03] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[10/27 18:28:03] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[10/27 18:28:03] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.275 | 72.037 | 42.332 | 16.411 | 36.856 | 43.029 |
[10/27 18:28:03] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| vehicles   | 42.862 | people     | 33.861 | animals    | 47.103 |
[10/27 18:28:03] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.639 | 79.619 | 40.524 | 32.827 | 38.488 | 52.644 |
[10/27 18:28:03] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| vehicles   | 39.933 | people     | 36.149 | animals    | 54.834 |
[10/27 18:28:03] d2.evaluation.f1score_evaluator INFO: Preparing results for COCO format ...
[10/27 18:28:03] d2.evaluation.f1score_evaluator INFO: Evaluating predictions ...
[10/27 18:28:04] d2.evaluation.f1score_evaluator INFO: Evaluation results for F1-score: 
|  F1-all  |  F1-0.5  |  F1-0.75  |  F1-small  |  F1-medium  |  F1-large  |
|:--------:|:--------:|:---------:|:----------:|:-----------:|:----------:|
|  0.101   |  0.159   |   0.109   |   0.001    |    0.048    |   0.064    |
[10/27 18:28:04] d2.engine.defaults INFO: Evaluation results for minicoco_val in csv format:
[10/27 18:28:04] d2.evaluation.testing INFO: copypaste: Task: bbox
[10/27 18:28:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[10/27 18:28:04] d2.evaluation.testing INFO: copypaste: 41.2753,72.0365,42.3321,16.4109,36.8557,43.0286
[10/27 18:28:04] d2.evaluation.testing INFO: copypaste: Task: segm
[10/27 18:28:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[10/27 18:28:04] d2.evaluation.testing INFO: copypaste: 43.6388,79.6193,40.5242,32.8267,38.4882,52.6438
[10/27 18:28:04] d2.evaluation.testing INFO: copypaste: Task: f1-segm
[10/27 18:28:04] d2.evaluation.testing INFO: copypaste: 
[10/27 18:28:04] d2.evaluation.testing INFO: copypaste: 
[10/27 18:31:36] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 18:31:37] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[10/27 18:31:37] detectron2 INFO: Command line arguments: Namespace(annotdir='default', config_file='/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/results/SOLOv2_minicoco_run2/model_0029999.pth'], resume=False)
[10/27 18:31:37] detectron2 INFO: Contents of args.config_file=/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml:
_BASE_: "Base-SOLOv2.yaml"
MODEL:
  WEIGHTS: '/root/data/pretrained_models/R-50.pkl'
  BACKBONE:
    FREEZE_AT: 5
  RESNETS:
    DEPTH: 50
  SOLOV2:
    NUM_CLASSES: 3
SOLVER:
  STEPS: (60000, 80000)
  MAX_ITER: 270000
  IMS_PER_BATCH: 4
  CHECKPOINT_PERIOD: 2500
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 640
  MASK_FORMAT: "bitmask"
DATASETS:
  TRAIN: ("minicoco_train",)
  TEST: ("minicoco_val",)
[10/27 18:31:37] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('minicoco_val',)
  TRAIN: ('minicoco_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: True
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: True
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    ANTI_ALIAS: False
    FREEZE_AT: 5
    NAME: build_resnet_fpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES: ['p3', 'p4', 'p5']
    LOSS_ON: False
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES: ['p2', 'p3', 'p4']
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION: (8, 32)
    POOLER_SCALES: (0.25, 0.125, 0.0625)
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES: (0.25,)
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: False
  BiFPN:
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CFS:
    ATTN_EMBED_SIZE: 64
    BACKBONE_MLP_HIDDEN_SIZE: 64
    BOTTLENECK_SIZE: 0
    DROPOUT: 0.0
    MASK_TO_FEATURE: lineintegral
    NORM: ln
    NUM_BACKBONE_LAYERS: 2
    NUM_HEADS: [8]
    SOLO_GT_SCHEME: weight
    THETA_SAMPLES: 16
    TRAIN_SOLO: True
    TRAIN_TRANSFORMER: False
    TRANSFORMER_ADVERSARIAL_LOSS: False
    TRANSFORMER_AUX_LOSS: False
    TRANSFORMER_GT_SCHEME: weight
    USE_ATTN_BOTTLENECK: [0]
  CONDINST:
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES: ['p3', 'p4', 'p5']
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: False
    MASK_HEAD:
      CHANNELS: 8
      DISABLE_REL_COORDS: False
      NUM_LAYERS: 3
      USE_FP16: False
    MASK_OUT_STRIDE: 4
    MAX_PROPOSALS: -1
  DEVICE: cuda
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  FCOS:
    CENTER_SAMPLE: True
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    USE_DEFORMABLE: False
    USE_RELU: True
    USE_SCALE: True
    YIELD_PROPOSAL: False
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  MEInst:
    AGNOSTIC: True
    CENTER_SAMPLE: True
    DIM_MASK: 60
    FLAG_PARAMETERS: False
    FPN_STRIDES: [8, 16, 32, 64, 128]
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    LAST_DEFORMABLE: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: False
    MASK_LOSS_TYPE: mse
    MASK_ON: True
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: True
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: False
    USE_GCN_IN_MASK: False
    USE_RELU: True
    USE_SCALE: True
    WHITEN: True
  META_ARCHITECTURE: SOLOv2
  MOBILENET: False
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SOLOV2:
    DEL_OLD_MASKS: False
    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]
    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))
    INSTANCE_CHANNELS: 512
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_MODE: iou
    KERN_TO_CATE: False
    KERN_TO_CATE_NUM_LAYERS: 0
    LOSS:
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: True
      FOCAL_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_CONTRAST: False
    MASK_CONTRAST_DIMS: 128
    MASK_CONTRAST_WEIGHT: 1.0
    MASK_HEAD_LEAKYRELU_ALPHA: 0.0
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    MASK_THR: 0.5
    MAX_PER_IMG: 100
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NORM: GN
    NUM_CLASSES: 3
    NUM_GRIDS: [40, 36, 24, 16, 12]
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    ONE_CLS_PER_LOC: False
    PRIOR_PROB: 0.01
    SCORE_THR: 0.1
    SEM_SEG: False
    SEM_SEG_NEG_TRAIN: False
    SEM_SEG_NUM_LAYERS: 2
    SEM_SEG_WEIGHT: 1.0
    SIGMA: 0.2
    TRAIN_BG_MASKS: False
    TRAIN_BG_MODE: dice
    TRAIN_BG_WEIGHT: 1.0
    TRAIN_VEC_FIELDS: False
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: True
    USE_DCN_IN_INSTANCE: False
    VEC_FIELDS_WEIGHT: 1.0
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  WEIGHTS: /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 2500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_IMAGE_NUM: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[10/27 18:31:37] detectron2 INFO: Full config saved to ./output/config.yaml
[10/27 18:31:37] d2.utils.env INFO: Using a generated random seed 38071898
[10/27 18:31:38] adet.modeling.solov2.solov2 WARNING: Not deleting old masks: this is default behavior in SOLO code.
[10/27 18:31:38] adet.modeling.solov2.solov2 WARNING: Ignore the above message if you're using SOLO as a sub-module.
[10/27 18:31:40] d2.engine.defaults INFO: Model:
SOLOv2(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (ins_head): SOLOv2InsHead(
    (cate_tower): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (kernel_tower): Sequential(
      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (cate_pred): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (mask_head): SOLOv2MaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
      )
      (1): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv0): Sequential(
          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (k2c_layers): ModuleList()
  (vec_fields_head): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
)
[10/27 18:31:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth ...
[10/27 18:31:40] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mvec_fields_head.{bias, weight}[0m
[10/27 18:31:40] d2.data.datasets.coco INFO: Loaded 326 images in COCO format from /root/data/miniCOCO/instances_val2021.json
[10/27 18:31:40] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  vehicles  | 104          |   people   | 98           |  animals   | 179          |
|            |              |            |              |            |              |
|   total    | 381          |            |              |            |              |[0m
[10/27 18:31:40] d2.data.common INFO: Serializing 326 elements to byte tensors and concatenating them all ...
[10/27 18:31:40] d2.data.common INFO: Serialized dataset takes 1.86 MiB
[10/27 18:31:40] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[10/27 18:32:12] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 18:32:14] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[10/27 18:32:14] detectron2 INFO: Command line arguments: Namespace(annotdir='default', config_file='/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/results/SOLOv2_minicoco_run2/model_0029999.pth'], resume=False)
[10/27 18:32:14] detectron2 INFO: Contents of args.config_file=/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml:
_BASE_: "Base-SOLOv2.yaml"
MODEL:
  WEIGHTS: '/root/data/pretrained_models/R-50.pkl'
  BACKBONE:
    FREEZE_AT: 5
  RESNETS:
    DEPTH: 50
  SOLOV2:
    NUM_CLASSES: 3
SOLVER:
  STEPS: (60000, 80000)
  MAX_ITER: 270000
  IMS_PER_BATCH: 4
  CHECKPOINT_PERIOD: 2500
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 640
  MASK_FORMAT: "bitmask"
DATASETS:
  TRAIN: ("minicoco_train",)
  TEST: ("minicoco_val",)
[10/27 18:32:14] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('minicoco_val',)
  TRAIN: ('minicoco_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: True
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: True
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    ANTI_ALIAS: False
    FREEZE_AT: 5
    NAME: build_resnet_fpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES: ['p3', 'p4', 'p5']
    LOSS_ON: False
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES: ['p2', 'p3', 'p4']
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION: (8, 32)
    POOLER_SCALES: (0.25, 0.125, 0.0625)
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES: (0.25,)
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: False
  BiFPN:
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CFS:
    ATTN_EMBED_SIZE: 64
    BACKBONE_MLP_HIDDEN_SIZE: 64
    BOTTLENECK_SIZE: 0
    DROPOUT: 0.0
    MASK_TO_FEATURE: lineintegral
    NORM: ln
    NUM_BACKBONE_LAYERS: 2
    NUM_HEADS: [8]
    SOLO_GT_SCHEME: weight
    THETA_SAMPLES: 16
    TRAIN_SOLO: True
    TRAIN_TRANSFORMER: False
    TRANSFORMER_ADVERSARIAL_LOSS: False
    TRANSFORMER_AUX_LOSS: False
    TRANSFORMER_GT_SCHEME: weight
    USE_ATTN_BOTTLENECK: [0]
  CONDINST:
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES: ['p3', 'p4', 'p5']
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: False
    MASK_HEAD:
      CHANNELS: 8
      DISABLE_REL_COORDS: False
      NUM_LAYERS: 3
      USE_FP16: False
    MASK_OUT_STRIDE: 4
    MAX_PROPOSALS: -1
  DEVICE: cuda
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  FCOS:
    CENTER_SAMPLE: True
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    USE_DEFORMABLE: False
    USE_RELU: True
    USE_SCALE: True
    YIELD_PROPOSAL: False
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  MEInst:
    AGNOSTIC: True
    CENTER_SAMPLE: True
    DIM_MASK: 60
    FLAG_PARAMETERS: False
    FPN_STRIDES: [8, 16, 32, 64, 128]
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    LAST_DEFORMABLE: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: False
    MASK_LOSS_TYPE: mse
    MASK_ON: True
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: True
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: False
    USE_GCN_IN_MASK: False
    USE_RELU: True
    USE_SCALE: True
    WHITEN: True
  META_ARCHITECTURE: SOLOv2
  MOBILENET: False
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SOLOV2:
    DEL_OLD_MASKS: False
    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]
    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))
    INSTANCE_CHANNELS: 512
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_MODE: iou
    KERN_TO_CATE: False
    KERN_TO_CATE_NUM_LAYERS: 0
    LOSS:
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: True
      FOCAL_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_CONTRAST: False
    MASK_CONTRAST_DIMS: 128
    MASK_CONTRAST_WEIGHT: 1.0
    MASK_HEAD_LEAKYRELU_ALPHA: 0.0
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    MASK_THR: 0.5
    MAX_PER_IMG: 100
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NORM: GN
    NUM_CLASSES: 3
    NUM_GRIDS: [40, 36, 24, 16, 12]
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    ONE_CLS_PER_LOC: False
    PRIOR_PROB: 0.01
    SCORE_THR: 0.1
    SEM_SEG: False
    SEM_SEG_NEG_TRAIN: False
    SEM_SEG_NUM_LAYERS: 2
    SEM_SEG_WEIGHT: 1.0
    SIGMA: 0.2
    TRAIN_BG_MASKS: False
    TRAIN_BG_MODE: dice
    TRAIN_BG_WEIGHT: 1.0
    TRAIN_VEC_FIELDS: False
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: True
    USE_DCN_IN_INSTANCE: False
    VEC_FIELDS_WEIGHT: 1.0
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  WEIGHTS: /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 2500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_IMAGE_NUM: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[10/27 18:32:14] detectron2 INFO: Full config saved to ./output/config.yaml
[10/27 18:32:14] d2.utils.env INFO: Using a generated random seed 14337754
[10/27 18:32:14] adet.modeling.solov2.solov2 WARNING: Not deleting old masks: this is default behavior in SOLO code.
[10/27 18:32:14] adet.modeling.solov2.solov2 WARNING: Ignore the above message if you're using SOLO as a sub-module.
[10/27 18:32:16] d2.engine.defaults INFO: Model:
SOLOv2(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (ins_head): SOLOv2InsHead(
    (cate_tower): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (kernel_tower): Sequential(
      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (cate_pred): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (mask_head): SOLOv2MaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
      )
      (1): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv0): Sequential(
          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (k2c_layers): ModuleList()
  (vec_fields_head): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
)
[10/27 18:32:16] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth ...
[10/27 18:32:16] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mvec_fields_head.{bias, weight}[0m
[10/27 18:32:16] d2.data.datasets.coco INFO: Loaded 326 images in COCO format from /root/data/miniCOCO/instances_val2021.json
[10/27 18:32:16] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  vehicles  | 104          |   people   | 98           |  animals   | 179          |
|            |              |            |              |            |              |
|   total    | 381          |            |              |            |              |[0m
[10/27 18:32:16] d2.data.common INFO: Serializing 326 elements to byte tensors and concatenating them all ...
[10/27 18:32:16] d2.data.common INFO: Serialized dataset takes 1.86 MiB
[10/27 18:32:16] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[10/27 18:33:54] d2.evaluation.evaluator INFO: Start inference on 326 images
[10/27 18:34:00] d2.evaluation.evaluator INFO: Inference done 11/326. 0.0405 s / img. ETA=0:00:15
[10/27 18:34:05] d2.evaluation.evaluator INFO: Inference done 117/326. 0.0399 s / img. ETA=0:00:09
[10/27 18:34:10] d2.evaluation.evaluator INFO: Inference done 221/326. 0.0403 s / img. ETA=0:00:05
[10/27 18:34:15] d2.evaluation.evaluator INFO: Inference done 326/326. 0.0402 s / img. ETA=0:00:00
[10/27 18:34:15] d2.evaluation.evaluator INFO: Total inference time: 0:00:16.142924 (0.050289 s / img per device, on 1 devices)
[10/27 18:34:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:12 (0.040166 s / img per device, on 1 devices)
[10/27 18:34:16] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[10/27 18:34:16] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[10/27 18:34:16] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[10/27 18:34:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.275 | 72.037 | 42.332 | 16.411 | 36.856 | 43.029 |
[10/27 18:34:16] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| vehicles   | 42.862 | people     | 33.861 | animals    | 47.103 |
[10/27 18:34:16] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.639 | 79.619 | 40.524 | 32.827 | 38.488 | 52.644 |
[10/27 18:34:16] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| vehicles   | 39.933 | people     | 36.149 | animals    | 54.834 |
[10/27 18:34:16] d2.evaluation.f1score_evaluator INFO: Preparing results for COCO format ...
[10/27 18:34:16] d2.evaluation.f1score_evaluator INFO: Evaluating predictions ...
[10/27 18:34:17] d2.evaluation.f1score_evaluator INFO: Evaluation results for F1-score: 
|  F1-all  |  F1-0.5  |  F1-0.75  |  F1-small  |  F1-medium  |  F1-large  |
|:--------:|:--------:|:---------:|:----------:|:-----------:|:----------:|
|  0.101   |  0.159   |   0.109   |   0.001    |    0.048    |   0.064    |
[10/27 18:34:17] d2.evaluation.tpmqscore_evaluator INFO: Preparing results for COCO format ...
[10/27 18:34:17] d2.evaluation.tpmqscore_evaluator INFO: Evaluating predictions ...
[10/27 21:14:51] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 21:14:53] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[10/27 21:14:53] detectron2 INFO: Command line arguments: Namespace(annotdir='default', config_file='/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/results/SOLOv2_minicoco_run2/model_0029999.pth'], resume=False)
[10/27 21:14:53] detectron2 INFO: Contents of args.config_file=/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml:
_BASE_: "Base-SOLOv2.yaml"
MODEL:
  WEIGHTS: '/root/data/pretrained_models/R-50.pkl'
  BACKBONE:
    FREEZE_AT: 5
  RESNETS:
    DEPTH: 50
  SOLOV2:
    NUM_CLASSES: 3
SOLVER:
  STEPS: (60000, 80000)
  MAX_ITER: 270000
  IMS_PER_BATCH: 4
  CHECKPOINT_PERIOD: 2500
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 640
  MASK_FORMAT: "bitmask"
DATASETS:
  TRAIN: ("minicoco_train",)
  TEST: ("minicoco_val",)
[10/27 21:14:53] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('minicoco_val',)
  TRAIN: ('minicoco_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: True
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: True
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    ANTI_ALIAS: False
    FREEZE_AT: 5
    NAME: build_resnet_fpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES: ['p3', 'p4', 'p5']
    LOSS_ON: False
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES: ['p2', 'p3', 'p4']
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION: (8, 32)
    POOLER_SCALES: (0.25, 0.125, 0.0625)
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES: (0.25,)
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: False
  BiFPN:
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CFS:
    ATTN_EMBED_SIZE: 64
    BACKBONE_MLP_HIDDEN_SIZE: 64
    BOTTLENECK_SIZE: 0
    DROPOUT: 0.0
    MASK_TO_FEATURE: lineintegral
    NORM: ln
    NUM_BACKBONE_LAYERS: 2
    NUM_HEADS: [8]
    SOLO_GT_SCHEME: weight
    THETA_SAMPLES: 16
    TRAIN_SOLO: True
    TRAIN_TRANSFORMER: False
    TRANSFORMER_ADVERSARIAL_LOSS: False
    TRANSFORMER_AUX_LOSS: False
    TRANSFORMER_GT_SCHEME: weight
    USE_ATTN_BOTTLENECK: [0]
  CONDINST:
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES: ['p3', 'p4', 'p5']
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: False
    MASK_HEAD:
      CHANNELS: 8
      DISABLE_REL_COORDS: False
      NUM_LAYERS: 3
      USE_FP16: False
    MASK_OUT_STRIDE: 4
    MAX_PROPOSALS: -1
  DEVICE: cuda
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  FCOS:
    CENTER_SAMPLE: True
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    USE_DEFORMABLE: False
    USE_RELU: True
    USE_SCALE: True
    YIELD_PROPOSAL: False
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  MEInst:
    AGNOSTIC: True
    CENTER_SAMPLE: True
    DIM_MASK: 60
    FLAG_PARAMETERS: False
    FPN_STRIDES: [8, 16, 32, 64, 128]
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    LAST_DEFORMABLE: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: False
    MASK_LOSS_TYPE: mse
    MASK_ON: True
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: True
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: False
    USE_GCN_IN_MASK: False
    USE_RELU: True
    USE_SCALE: True
    WHITEN: True
  META_ARCHITECTURE: SOLOv2
  MOBILENET: False
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SOLOV2:
    DEL_OLD_MASKS: False
    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]
    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))
    INSTANCE_CHANNELS: 512
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_MODE: iou
    KERN_TO_CATE: False
    KERN_TO_CATE_NUM_LAYERS: 0
    LOSS:
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: True
      FOCAL_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_CONTRAST: False
    MASK_CONTRAST_DIMS: 128
    MASK_CONTRAST_WEIGHT: 1.0
    MASK_HEAD_LEAKYRELU_ALPHA: 0.0
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    MASK_THR: 0.5
    MAX_PER_IMG: 100
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NORM: GN
    NUM_CLASSES: 3
    NUM_GRIDS: [40, 36, 24, 16, 12]
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    ONE_CLS_PER_LOC: False
    PRIOR_PROB: 0.01
    SCORE_THR: 0.1
    SEM_SEG: False
    SEM_SEG_NEG_TRAIN: False
    SEM_SEG_NUM_LAYERS: 2
    SEM_SEG_WEIGHT: 1.0
    SIGMA: 0.2
    TRAIN_BG_MASKS: False
    TRAIN_BG_MODE: dice
    TRAIN_BG_WEIGHT: 1.0
    TRAIN_VEC_FIELDS: False
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: True
    USE_DCN_IN_INSTANCE: False
    VEC_FIELDS_WEIGHT: 1.0
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  WEIGHTS: /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 2500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_IMAGE_NUM: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[10/27 21:14:53] detectron2 INFO: Full config saved to ./output/config.yaml
[10/27 21:14:53] d2.utils.env INFO: Using a generated random seed 53269524
[10/27 21:14:53] adet.modeling.solov2.solov2 WARNING: Not deleting old masks: this is default behavior in SOLO code.
[10/27 21:14:53] adet.modeling.solov2.solov2 WARNING: Ignore the above message if you're using SOLO as a sub-module.
[10/27 21:15:48] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 21:15:49] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[10/27 21:15:49] detectron2 INFO: Command line arguments: Namespace(annotdir='default', config_file='/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/results/SOLOv2_minicoco_run2/model_0029999.pth'], resume=False)
[10/27 21:15:49] detectron2 INFO: Contents of args.config_file=/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml:
_BASE_: "Base-SOLOv2.yaml"
MODEL:
  WEIGHTS: '/root/data/pretrained_models/R-50.pkl'
  BACKBONE:
    FREEZE_AT: 5
  RESNETS:
    DEPTH: 50
  SOLOV2:
    NUM_CLASSES: 3
SOLVER:
  STEPS: (60000, 80000)
  MAX_ITER: 270000
  IMS_PER_BATCH: 4
  CHECKPOINT_PERIOD: 2500
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 640
  MASK_FORMAT: "bitmask"
DATASETS:
  TRAIN: ("minicoco_train",)
  TEST: ("minicoco_val",)
[10/27 21:15:49] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('minicoco_val',)
  TRAIN: ('minicoco_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: True
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: True
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    ANTI_ALIAS: False
    FREEZE_AT: 5
    NAME: build_resnet_fpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES: ['p3', 'p4', 'p5']
    LOSS_ON: False
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES: ['p2', 'p3', 'p4']
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION: (8, 32)
    POOLER_SCALES: (0.25, 0.125, 0.0625)
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES: (0.25,)
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: False
  BiFPN:
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CFS:
    ATTN_EMBED_SIZE: 64
    BACKBONE_MLP_HIDDEN_SIZE: 64
    BOTTLENECK_SIZE: 0
    DROPOUT: 0.0
    MASK_TO_FEATURE: lineintegral
    NORM: ln
    NUM_BACKBONE_LAYERS: 2
    NUM_HEADS: [8]
    SOLO_GT_SCHEME: weight
    THETA_SAMPLES: 16
    TRAIN_SOLO: True
    TRAIN_TRANSFORMER: False
    TRANSFORMER_ADVERSARIAL_LOSS: False
    TRANSFORMER_AUX_LOSS: False
    TRANSFORMER_GT_SCHEME: weight
    USE_ATTN_BOTTLENECK: [0]
  CONDINST:
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES: ['p3', 'p4', 'p5']
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: False
    MASK_HEAD:
      CHANNELS: 8
      DISABLE_REL_COORDS: False
      NUM_LAYERS: 3
      USE_FP16: False
    MASK_OUT_STRIDE: 4
    MAX_PROPOSALS: -1
  DEVICE: cuda
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  FCOS:
    CENTER_SAMPLE: True
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    USE_DEFORMABLE: False
    USE_RELU: True
    USE_SCALE: True
    YIELD_PROPOSAL: False
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  MEInst:
    AGNOSTIC: True
    CENTER_SAMPLE: True
    DIM_MASK: 60
    FLAG_PARAMETERS: False
    FPN_STRIDES: [8, 16, 32, 64, 128]
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    LAST_DEFORMABLE: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: False
    MASK_LOSS_TYPE: mse
    MASK_ON: True
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: True
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: False
    USE_GCN_IN_MASK: False
    USE_RELU: True
    USE_SCALE: True
    WHITEN: True
  META_ARCHITECTURE: SOLOv2
  MOBILENET: False
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SOLOV2:
    DEL_OLD_MASKS: False
    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]
    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))
    INSTANCE_CHANNELS: 512
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_MODE: iou
    KERN_TO_CATE: False
    KERN_TO_CATE_NUM_LAYERS: 0
    LOSS:
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: True
      FOCAL_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_CONTRAST: False
    MASK_CONTRAST_DIMS: 128
    MASK_CONTRAST_WEIGHT: 1.0
    MASK_HEAD_LEAKYRELU_ALPHA: 0.0
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    MASK_THR: 0.5
    MAX_PER_IMG: 100
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NORM: GN
    NUM_CLASSES: 3
    NUM_GRIDS: [40, 36, 24, 16, 12]
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    ONE_CLS_PER_LOC: False
    PRIOR_PROB: 0.01
    SCORE_THR: 0.1
    SEM_SEG: False
    SEM_SEG_NEG_TRAIN: False
    SEM_SEG_NUM_LAYERS: 2
    SEM_SEG_WEIGHT: 1.0
    SIGMA: 0.2
    TRAIN_BG_MASKS: False
    TRAIN_BG_MODE: dice
    TRAIN_BG_WEIGHT: 1.0
    TRAIN_VEC_FIELDS: False
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: True
    USE_DCN_IN_INSTANCE: False
    VEC_FIELDS_WEIGHT: 1.0
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  WEIGHTS: /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 2500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_IMAGE_NUM: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[10/27 21:15:49] detectron2 INFO: Full config saved to ./output/config.yaml
[10/27 21:15:49] d2.utils.env INFO: Using a generated random seed 49932236
[10/27 21:15:50] adet.modeling.solov2.solov2 WARNING: Not deleting old masks: this is default behavior in SOLO code.
[10/27 21:15:50] adet.modeling.solov2.solov2 WARNING: Ignore the above message if you're using SOLO as a sub-module.
[10/27 21:15:52] d2.engine.defaults INFO: Model:
SOLOv2(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (ins_head): SOLOv2InsHead(
    (cate_tower): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (kernel_tower): Sequential(
      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (cate_pred): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (mask_head): SOLOv2MaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
      )
      (1): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv0): Sequential(
          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (k2c_layers): ModuleList()
  (vec_fields_head): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
)
[10/27 21:15:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth ...
[10/27 21:15:52] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mvec_fields_head.{bias, weight}[0m
[10/27 21:15:52] d2.data.datasets.coco INFO: Loaded 326 images in COCO format from /root/data/miniCOCO/instances_val2021.json
[10/27 21:15:52] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  vehicles  | 104          |   people   | 98           |  animals   | 179          |
|            |              |            |              |            |              |
|   total    | 381          |            |              |            |              |[0m
[10/27 21:15:52] d2.data.common INFO: Serializing 326 elements to byte tensors and concatenating them all ...
[10/27 21:15:52] d2.data.common INFO: Serialized dataset takes 1.86 MiB
[10/27 21:15:52] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[10/27 21:15:52] d2.evaluation.evaluator INFO: Start inference on 326 images
[10/27 21:17:03] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 21:17:04] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[10/27 21:17:04] detectron2 INFO: Command line arguments: Namespace(annotdir='default', config_file='/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/results/SOLOv2_minicoco_run2/model_0029999.pth'], resume=False)
[10/27 21:17:04] detectron2 INFO: Contents of args.config_file=/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml:
_BASE_: "Base-SOLOv2.yaml"
MODEL:
  WEIGHTS: '/root/data/pretrained_models/R-50.pkl'
  BACKBONE:
    FREEZE_AT: 5
  RESNETS:
    DEPTH: 50
  SOLOV2:
    NUM_CLASSES: 3
SOLVER:
  STEPS: (60000, 80000)
  MAX_ITER: 270000
  IMS_PER_BATCH: 4
  CHECKPOINT_PERIOD: 2500
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 640
  MASK_FORMAT: "bitmask"
DATASETS:
  TRAIN: ("minicoco_train",)
  TEST: ("minicoco_val",)
[10/27 21:17:04] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('minicoco_val',)
  TRAIN: ('minicoco_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: True
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: True
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    ANTI_ALIAS: False
    FREEZE_AT: 5
    NAME: build_resnet_fpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES: ['p3', 'p4', 'p5']
    LOSS_ON: False
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES: ['p2', 'p3', 'p4']
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION: (8, 32)
    POOLER_SCALES: (0.25, 0.125, 0.0625)
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES: (0.25,)
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: False
  BiFPN:
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CFS:
    ATTN_EMBED_SIZE: 64
    BACKBONE_MLP_HIDDEN_SIZE: 64
    BOTTLENECK_SIZE: 0
    DROPOUT: 0.0
    MASK_TO_FEATURE: lineintegral
    NORM: ln
    NUM_BACKBONE_LAYERS: 2
    NUM_HEADS: [8]
    SOLO_GT_SCHEME: weight
    THETA_SAMPLES: 16
    TRAIN_SOLO: True
    TRAIN_TRANSFORMER: False
    TRANSFORMER_ADVERSARIAL_LOSS: False
    TRANSFORMER_AUX_LOSS: False
    TRANSFORMER_GT_SCHEME: weight
    USE_ATTN_BOTTLENECK: [0]
  CONDINST:
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES: ['p3', 'p4', 'p5']
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: False
    MASK_HEAD:
      CHANNELS: 8
      DISABLE_REL_COORDS: False
      NUM_LAYERS: 3
      USE_FP16: False
    MASK_OUT_STRIDE: 4
    MAX_PROPOSALS: -1
  DEVICE: cuda
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  FCOS:
    CENTER_SAMPLE: True
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    USE_DEFORMABLE: False
    USE_RELU: True
    USE_SCALE: True
    YIELD_PROPOSAL: False
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  MEInst:
    AGNOSTIC: True
    CENTER_SAMPLE: True
    DIM_MASK: 60
    FLAG_PARAMETERS: False
    FPN_STRIDES: [8, 16, 32, 64, 128]
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    LAST_DEFORMABLE: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: False
    MASK_LOSS_TYPE: mse
    MASK_ON: True
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: True
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: False
    USE_GCN_IN_MASK: False
    USE_RELU: True
    USE_SCALE: True
    WHITEN: True
  META_ARCHITECTURE: SOLOv2
  MOBILENET: False
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SOLOV2:
    DEL_OLD_MASKS: False
    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]
    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))
    INSTANCE_CHANNELS: 512
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_MODE: iou
    KERN_TO_CATE: False
    KERN_TO_CATE_NUM_LAYERS: 0
    LOSS:
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: True
      FOCAL_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_CONTRAST: False
    MASK_CONTRAST_DIMS: 128
    MASK_CONTRAST_WEIGHT: 1.0
    MASK_HEAD_LEAKYRELU_ALPHA: 0.0
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    MASK_THR: 0.5
    MAX_PER_IMG: 100
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NORM: GN
    NUM_CLASSES: 3
    NUM_GRIDS: [40, 36, 24, 16, 12]
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    ONE_CLS_PER_LOC: False
    PRIOR_PROB: 0.01
    SCORE_THR: 0.1
    SEM_SEG: False
    SEM_SEG_NEG_TRAIN: False
    SEM_SEG_NUM_LAYERS: 2
    SEM_SEG_WEIGHT: 1.0
    SIGMA: 0.2
    TRAIN_BG_MASKS: False
    TRAIN_BG_MODE: dice
    TRAIN_BG_WEIGHT: 1.0
    TRAIN_VEC_FIELDS: False
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: True
    USE_DCN_IN_INSTANCE: False
    VEC_FIELDS_WEIGHT: 1.0
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  WEIGHTS: /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 2500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_IMAGE_NUM: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[10/27 21:17:04] detectron2 INFO: Full config saved to ./output/config.yaml
[10/27 21:17:04] d2.utils.env INFO: Using a generated random seed 4894956
[10/27 21:17:05] adet.modeling.solov2.solov2 WARNING: Not deleting old masks: this is default behavior in SOLO code.
[10/27 21:17:05] adet.modeling.solov2.solov2 WARNING: Ignore the above message if you're using SOLO as a sub-module.
[10/27 21:17:07] d2.engine.defaults INFO: Model:
SOLOv2(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (ins_head): SOLOv2InsHead(
    (cate_tower): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (kernel_tower): Sequential(
      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (cate_pred): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (mask_head): SOLOv2MaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
      )
      (1): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv0): Sequential(
          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (k2c_layers): ModuleList()
  (vec_fields_head): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
)
[10/27 21:17:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth ...
[10/27 21:17:07] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mvec_fields_head.{bias, weight}[0m
[10/27 21:17:07] d2.data.datasets.coco INFO: Loaded 326 images in COCO format from /root/data/miniCOCO/instances_val2021.json
[10/27 21:17:07] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  vehicles  | 104          |   people   | 98           |  animals   | 179          |
|            |              |            |              |            |              |
|   total    | 381          |            |              |            |              |[0m
[10/27 21:17:07] d2.data.common INFO: Serializing 326 elements to byte tensors and concatenating them all ...
[10/27 21:17:07] d2.data.common INFO: Serialized dataset takes 1.86 MiB
[10/27 21:17:07] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[10/27 21:17:07] d2.evaluation.evaluator INFO: Start inference on 326 images
[10/27 21:17:28] d2.evaluation.evaluator INFO: Inference done 1/326. 19.6737 s / img. ETA=1:52:43
[10/27 21:17:33] d2.evaluation.evaluator INFO: Inference done 105/326. 0.0400 s / img. ETA=0:00:10
[10/27 21:17:38] d2.evaluation.evaluator INFO: Inference done 208/326. 0.0404 s / img. ETA=0:00:05
[10/27 21:17:43] d2.evaluation.evaluator INFO: Inference done 313/326. 0.0403 s / img. ETA=0:00:00
[10/27 21:17:44] d2.evaluation.evaluator INFO: Total inference time: 0:00:16.156708 (0.050332 s / img per device, on 1 devices)
[10/27 21:17:44] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:12 (0.040269 s / img per device, on 1 devices)
[10/27 21:17:44] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[10/27 21:17:44] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[10/27 21:17:45] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[10/27 21:17:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.275 | 72.037 | 42.332 | 16.411 | 36.856 | 43.029 |
[10/27 21:17:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| vehicles   | 42.862 | people     | 33.861 | animals    | 47.103 |
[10/27 21:17:45] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.639 | 79.619 | 40.524 | 32.827 | 38.488 | 52.644 |
[10/27 21:17:45] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| vehicles   | 39.933 | people     | 36.149 | animals    | 54.834 |
[10/27 21:17:45] d2.evaluation.f1score_evaluator INFO: Preparing results for COCO format ...
[10/27 21:17:45] d2.evaluation.f1score_evaluator INFO: Evaluating predictions ...
[10/27 21:17:46] d2.evaluation.f1score_evaluator INFO: Evaluation results for F1-score: 
|  F1-all  |  F1-0.5  |  F1-0.75  |  F1-small  |  F1-medium  |  F1-large  |
|:--------:|:--------:|:---------:|:----------:|:-----------:|:----------:|
|  0.101   |  0.159   |   0.109   |   0.001    |    0.048    |   0.064    |
[10/27 21:17:46] d2.evaluation.tpmqscore_evaluator INFO: Preparing results for COCO format ...
[10/27 21:17:46] d2.evaluation.tpmqscore_evaluator INFO: Evaluating predictions ...
[10/27 21:22:34] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 21:22:36] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[10/27 21:22:36] detectron2 INFO: Command line arguments: Namespace(annotdir='default', config_file='/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/results/SOLOv2_minicoco_run2/model_0029999.pth'], resume=False)
[10/27 21:22:36] detectron2 INFO: Contents of args.config_file=/root/code/detectron2/adet/configs/SOLOv2/R50_miniCOCO.yaml:
_BASE_: "Base-SOLOv2.yaml"
MODEL:
  WEIGHTS: '/root/data/pretrained_models/R-50.pkl'
  BACKBONE:
    FREEZE_AT: 5
  RESNETS:
    DEPTH: 50
  SOLOV2:
    NUM_CLASSES: 3
SOLVER:
  STEPS: (60000, 80000)
  MAX_ITER: 270000
  IMS_PER_BATCH: 4
  CHECKPOINT_PERIOD: 2500
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 640
  MASK_FORMAT: "bitmask"
DATASETS:
  TRAIN: ("minicoco_train",)
  TEST: ("minicoco_val",)
[10/27 21:22:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('minicoco_val',)
  TRAIN: ('minicoco_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: True
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: True
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    ANTI_ALIAS: False
    FREEZE_AT: 5
    NAME: build_resnet_fpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES: ['p3', 'p4', 'p5']
    LOSS_ON: False
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES: ['p2', 'p3', 'p4']
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION: (8, 32)
    POOLER_SCALES: (0.25, 0.125, 0.0625)
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES: (0.25,)
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: False
  BiFPN:
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CFS:
    ATTN_EMBED_SIZE: 64
    BACKBONE_MLP_HIDDEN_SIZE: 64
    BOTTLENECK_SIZE: 0
    DROPOUT: 0.0
    MASK_TO_FEATURE: lineintegral
    NORM: ln
    NUM_BACKBONE_LAYERS: 2
    NUM_HEADS: [8]
    SOLO_GT_SCHEME: weight
    THETA_SAMPLES: 16
    TRAIN_SOLO: True
    TRAIN_TRANSFORMER: False
    TRANSFORMER_ADVERSARIAL_LOSS: False
    TRANSFORMER_AUX_LOSS: False
    TRANSFORMER_GT_SCHEME: weight
    USE_ATTN_BOTTLENECK: [0]
  CONDINST:
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES: ['p3', 'p4', 'p5']
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: False
    MASK_HEAD:
      CHANNELS: 8
      DISABLE_REL_COORDS: False
      NUM_LAYERS: 3
      USE_FP16: False
    MASK_OUT_STRIDE: 4
    MAX_PROPOSALS: -1
  DEVICE: cuda
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  FCOS:
    CENTER_SAMPLE: True
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    USE_DEFORMABLE: False
    USE_RELU: True
    USE_SCALE: True
    YIELD_PROPOSAL: False
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  MEInst:
    AGNOSTIC: True
    CENTER_SAMPLE: True
    DIM_MASK: 60
    FLAG_PARAMETERS: False
    FPN_STRIDES: [8, 16, 32, 64, 128]
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    LAST_DEFORMABLE: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: False
    MASK_LOSS_TYPE: mse
    MASK_ON: True
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: True
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: False
    USE_GCN_IN_MASK: False
    USE_RELU: True
    USE_SCALE: True
    WHITEN: True
  META_ARCHITECTURE: SOLOv2
  MOBILENET: False
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SOLOV2:
    DEL_OLD_MASKS: False
    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]
    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))
    INSTANCE_CHANNELS: 512
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_MODE: iou
    KERN_TO_CATE: False
    KERN_TO_CATE_NUM_LAYERS: 0
    LOSS:
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: True
      FOCAL_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_CONTRAST: False
    MASK_CONTRAST_DIMS: 128
    MASK_CONTRAST_WEIGHT: 1.0
    MASK_HEAD_LEAKYRELU_ALPHA: 0.0
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    MASK_THR: 0.5
    MAX_PER_IMG: 100
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NORM: GN
    NUM_CLASSES: 3
    NUM_GRIDS: [40, 36, 24, 16, 12]
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    ONE_CLS_PER_LOC: False
    PRIOR_PROB: 0.01
    SCORE_THR: 0.1
    SEM_SEG: False
    SEM_SEG_NEG_TRAIN: False
    SEM_SEG_NUM_LAYERS: 2
    SEM_SEG_WEIGHT: 1.0
    SIGMA: 0.2
    TRAIN_BG_MASKS: False
    TRAIN_BG_MODE: dice
    TRAIN_BG_WEIGHT: 1.0
    TRAIN_VEC_FIELDS: False
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: True
    USE_DCN_IN_INSTANCE: False
    VEC_FIELDS_WEIGHT: 1.0
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  WEIGHTS: /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 2500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_IMAGE_NUM: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[10/27 21:22:36] detectron2 INFO: Full config saved to ./output/config.yaml
[10/27 21:22:36] d2.utils.env INFO: Using a generated random seed 36286544
[10/27 21:22:36] adet.modeling.solov2.solov2 WARNING: Not deleting old masks: this is default behavior in SOLO code.
[10/27 21:22:36] adet.modeling.solov2.solov2 WARNING: Ignore the above message if you're using SOLO as a sub-module.
[10/27 21:22:38] d2.engine.defaults INFO: Model:
SOLOv2(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (ins_head): SOLOv2InsHead(
    (cate_tower): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (kernel_tower): Sequential(
      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): GroupNorm(32, 512, eps=1e-05, affine=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): GroupNorm(32, 512, eps=1e-05, affine=True)
      (11): ReLU(inplace=True)
    )
    (cate_pred): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (mask_head): SOLOv2MaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
      )
      (1): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv0): Sequential(
          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
          (2): ReLU()
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (k2c_layers): ModuleList()
  (vec_fields_head): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
)
[10/27 21:22:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/data/results/SOLOv2_minicoco_run2/model_0029999.pth ...
[10/27 21:22:38] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mvec_fields_head.{bias, weight}[0m
[10/27 21:22:38] d2.data.datasets.coco INFO: Loaded 326 images in COCO format from /root/data/miniCOCO/instances_val2021.json
[10/27 21:22:38] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  vehicles  | 104          |   people   | 98           |  animals   | 179          |
|            |              |            |              |            |              |
|   total    | 381          |            |              |            |              |[0m
[10/27 21:22:38] d2.data.common INFO: Serializing 326 elements to byte tensors and concatenating them all ...
[10/27 21:22:38] d2.data.common INFO: Serialized dataset takes 1.86 MiB
[10/27 21:22:38] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[10/27 21:22:39] d2.evaluation.evaluator INFO: Start inference on 326 images
[10/27 21:22:47] d2.evaluation.evaluator INFO: Inference done 1/326. 7.2091 s / img. ETA=0:44:11
[10/27 21:22:52] d2.evaluation.evaluator INFO: Inference done 105/326. 0.0400 s / img. ETA=0:00:10
[02/09 21:12:38] detectron2 INFO: Rank of current process: 0. World size: 1
[02/09 21:12:39] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[02/09 21:12:39] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/pretrained_models/mask_rcnn_r50_fpn.pkl'], resume=False)
[02/09 21:12:39] detectron2 INFO: Contents of args.config_file=configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/09 21:12:39] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('coco_2017_val',)
  TRAIN: ('coco_2017_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /root/data/pretrained_models/mask_rcnn_r50_fpn.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.02
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (210000, 250000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[02/09 21:12:39] detectron2 INFO: Full config saved to ./output/config.yaml
[02/09 21:12:39] d2.utils.env INFO: Using a generated random seed 39260507
[02/09 21:12:41] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[02/09 21:12:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/data/pretrained_models/mask_rcnn_r50_fpn.pkl ...
[02/09 21:12:42] fvcore.common.checkpoint INFO: Reading a file from 'Detectron2 Model Zoo'
[02/09 21:12:43] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from /root/data/mainData/coco/annotations/instances_val2017.json
[02/09 21:12:43] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[02/09 21:12:43] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[02/09 21:12:43] d2.data.common INFO: Serialized dataset takes 19.15 MiB
[02/09 21:12:43] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/09 21:12:45] d2.evaluation.evaluator INFO: Start inference on 5000 images
[02/09 21:12:47] d2.evaluation.evaluator INFO: Inference done 11/5000. 0.0468 s / img. ETA=0:07:22
[02/09 21:12:52] d2.evaluation.evaluator INFO: Inference done 71/5000. 0.0474 s / img. ETA=0:06:57
[02/09 21:12:57] d2.evaluation.evaluator INFO: Inference done 124/5000. 0.0473 s / img. ETA=0:07:18
[02/09 21:13:02] d2.evaluation.evaluator INFO: Inference done 175/5000. 0.0474 s / img. ETA=0:07:27
[02/09 21:13:07] d2.evaluation.evaluator INFO: Inference done 234/5000. 0.0474 s / img. ETA=0:07:15
[02/09 21:13:12] d2.evaluation.evaluator INFO: Inference done 287/5000. 0.0474 s / img. ETA=0:07:13
[02/09 21:13:17] d2.evaluation.evaluator INFO: Inference done 339/5000. 0.0476 s / img. ETA=0:07:12
[02/09 21:13:22] d2.evaluation.evaluator INFO: Inference done 398/5000. 0.0475 s / img. ETA=0:07:01
[02/09 21:13:27] d2.evaluation.evaluator INFO: Inference done 459/5000. 0.0474 s / img. ETA=0:06:50
[02/09 21:13:32] d2.evaluation.evaluator INFO: Inference done 513/5000. 0.0475 s / img. ETA=0:06:46
[02/09 21:13:37] d2.evaluation.evaluator INFO: Inference done 566/5000. 0.0475 s / img. ETA=0:06:44
[02/09 21:13:42] d2.evaluation.evaluator INFO: Inference done 615/5000. 0.0475 s / img. ETA=0:06:43
[02/09 21:13:48] d2.evaluation.evaluator INFO: Inference done 664/5000. 0.0476 s / img. ETA=0:06:42
[02/09 21:13:53] d2.evaluation.evaluator INFO: Inference done 719/5000. 0.0476 s / img. ETA=0:06:37
[02/09 21:13:58] d2.evaluation.evaluator INFO: Inference done 779/5000. 0.0476 s / img. ETA=0:06:28
[02/09 21:14:03] d2.evaluation.evaluator INFO: Inference done 834/5000. 0.0476 s / img. ETA=0:06:24
[02/09 21:14:08] d2.evaluation.evaluator INFO: Inference done 892/5000. 0.0477 s / img. ETA=0:06:17
[02/09 21:14:13] d2.evaluation.evaluator INFO: Inference done 951/5000. 0.0477 s / img. ETA=0:06:10
[02/09 21:14:18] d2.evaluation.evaluator INFO: Inference done 1008/5000. 0.0477 s / img. ETA=0:06:04
[02/09 21:14:23] d2.evaluation.evaluator INFO: Inference done 1062/5000. 0.0477 s / img. ETA=0:06:00
[02/09 21:14:28] d2.evaluation.evaluator INFO: Inference done 1121/5000. 0.0477 s / img. ETA=0:05:54
[02/09 21:14:33] d2.evaluation.evaluator INFO: Inference done 1167/5000. 0.0477 s / img. ETA=0:05:52
[02/09 21:14:38] d2.evaluation.evaluator INFO: Inference done 1217/5000. 0.0478 s / img. ETA=0:05:49
[02/09 21:14:43] d2.evaluation.evaluator INFO: Inference done 1255/5000. 0.0486 s / img. ETA=0:05:50
[02/09 21:14:48] d2.evaluation.evaluator INFO: Inference done 1295/5000. 0.0499 s / img. ETA=0:05:50
[02/09 21:14:53] d2.evaluation.evaluator INFO: Inference done 1332/5000. 0.0510 s / img. ETA=0:05:51
[02/09 21:14:59] d2.evaluation.evaluator INFO: Inference done 1368/5000. 0.0522 s / img. ETA=0:05:52
[02/09 21:15:04] d2.evaluation.evaluator INFO: Inference done 1407/5000. 0.0532 s / img. ETA=0:05:51
[02/09 21:15:09] d2.evaluation.evaluator INFO: Inference done 1445/5000. 0.0541 s / img. ETA=0:05:51
[02/09 21:15:14] d2.evaluation.evaluator INFO: Inference done 1481/5000. 0.0551 s / img. ETA=0:05:51
[02/09 21:15:19] d2.evaluation.evaluator INFO: Inference done 1517/5000. 0.0560 s / img. ETA=0:05:51
[02/09 21:15:24] d2.evaluation.evaluator INFO: Inference done 1553/5000. 0.0568 s / img. ETA=0:05:50
[02/09 21:15:29] d2.evaluation.evaluator INFO: Inference done 1588/5000. 0.0576 s / img. ETA=0:05:50
[02/09 21:15:34] d2.evaluation.evaluator INFO: Inference done 1622/5000. 0.0585 s / img. ETA=0:05:50
[02/09 21:15:39] d2.evaluation.evaluator INFO: Inference done 1660/5000. 0.0593 s / img. ETA=0:05:48
[02/09 21:15:44] d2.evaluation.evaluator INFO: Inference done 1696/5000. 0.0600 s / img. ETA=0:05:47
[02/09 21:15:49] d2.evaluation.evaluator INFO: Inference done 1734/5000. 0.0607 s / img. ETA=0:05:45
[02/09 21:15:54] d2.evaluation.evaluator INFO: Inference done 1775/5000. 0.0614 s / img. ETA=0:05:42
[02/09 21:15:59] d2.evaluation.evaluator INFO: Inference done 1812/5000. 0.0620 s / img. ETA=0:05:40
[02/09 21:16:04] d2.evaluation.evaluator INFO: Inference done 1845/5000. 0.0625 s / img. ETA=0:05:39
[02/09 21:16:10] d2.evaluation.evaluator INFO: Inference done 1880/5000. 0.0631 s / img. ETA=0:05:38
[02/09 21:16:15] d2.evaluation.evaluator INFO: Inference done 1921/5000. 0.0637 s / img. ETA=0:05:34
[02/09 21:16:20] d2.evaluation.evaluator INFO: Inference done 1961/5000. 0.0643 s / img. ETA=0:05:31
[02/09 21:16:25] d2.evaluation.evaluator INFO: Inference done 1995/5000. 0.0648 s / img. ETA=0:05:30
[02/09 21:16:30] d2.evaluation.evaluator INFO: Inference done 2032/5000. 0.0652 s / img. ETA=0:05:27
[02/09 21:16:35] d2.evaluation.evaluator INFO: Inference done 2074/5000. 0.0656 s / img. ETA=0:05:23
[02/09 21:16:40] d2.evaluation.evaluator INFO: Inference done 2110/5000. 0.0660 s / img. ETA=0:05:21
[02/09 21:16:45] d2.evaluation.evaluator INFO: Inference done 2149/5000. 0.0665 s / img. ETA=0:05:17
[02/09 21:16:50] d2.evaluation.evaluator INFO: Inference done 2188/5000. 0.0669 s / img. ETA=0:05:14
[02/09 21:16:55] d2.evaluation.evaluator INFO: Inference done 2224/5000. 0.0673 s / img. ETA=0:05:11
[02/09 21:17:00] d2.evaluation.evaluator INFO: Inference done 2260/5000. 0.0677 s / img. ETA=0:05:08
[02/09 21:17:06] d2.evaluation.evaluator INFO: Inference done 2299/5000. 0.0683 s / img. ETA=0:05:05
[02/09 21:17:11] d2.evaluation.evaluator INFO: Inference done 2338/5000. 0.0687 s / img. ETA=0:05:01
[02/09 21:17:16] d2.evaluation.evaluator INFO: Inference done 2377/5000. 0.0690 s / img. ETA=0:04:57
[02/09 21:17:21] d2.evaluation.evaluator INFO: Inference done 2415/5000. 0.0693 s / img. ETA=0:04:54
[02/09 21:17:26] d2.evaluation.evaluator INFO: Inference done 2451/5000. 0.0696 s / img. ETA=0:04:51
[02/09 21:17:31] d2.evaluation.evaluator INFO: Inference done 2487/5000. 0.0700 s / img. ETA=0:04:48
[02/09 21:17:36] d2.evaluation.evaluator INFO: Inference done 2523/5000. 0.0703 s / img. ETA=0:04:45
[02/09 21:17:41] d2.evaluation.evaluator INFO: Inference done 2561/5000. 0.0705 s / img. ETA=0:04:41
[02/09 21:17:46] d2.evaluation.evaluator INFO: Inference done 2597/5000. 0.0707 s / img. ETA=0:04:37
[02/09 21:17:51] d2.evaluation.evaluator INFO: Inference done 2632/5000. 0.0710 s / img. ETA=0:04:34
[02/09 21:17:56] d2.evaluation.evaluator INFO: Inference done 2671/5000. 0.0713 s / img. ETA=0:04:30
[02/09 21:18:01] d2.evaluation.evaluator INFO: Inference done 2705/5000. 0.0716 s / img. ETA=0:04:27
[02/09 21:18:07] d2.evaluation.evaluator INFO: Inference done 2745/5000. 0.0718 s / img. ETA=0:04:23
[02/09 21:18:12] d2.evaluation.evaluator INFO: Inference done 2783/5000. 0.0720 s / img. ETA=0:04:19
[02/09 21:18:17] d2.evaluation.evaluator INFO: Inference done 2818/5000. 0.0723 s / img. ETA=0:04:16
[02/09 21:18:22] d2.evaluation.evaluator INFO: Inference done 2853/5000. 0.0727 s / img. ETA=0:04:12
[02/09 21:18:27] d2.evaluation.evaluator INFO: Inference done 2892/5000. 0.0729 s / img. ETA=0:04:08
[02/09 21:18:32] d2.evaluation.evaluator INFO: Inference done 2926/5000. 0.0732 s / img. ETA=0:04:05
[02/09 21:18:37] d2.evaluation.evaluator INFO: Inference done 2963/5000. 0.0735 s / img. ETA=0:04:01
[02/09 21:18:42] d2.evaluation.evaluator INFO: Inference done 3003/5000. 0.0736 s / img. ETA=0:03:56
[02/09 21:18:47] d2.evaluation.evaluator INFO: Inference done 3040/5000. 0.0739 s / img. ETA=0:03:52
[02/09 21:18:52] d2.evaluation.evaluator INFO: Inference done 3079/5000. 0.0741 s / img. ETA=0:03:48
[02/09 21:18:57] d2.evaluation.evaluator INFO: Inference done 3120/5000. 0.0743 s / img. ETA=0:03:43
[02/09 21:19:02] d2.evaluation.evaluator INFO: Inference done 3157/5000. 0.0745 s / img. ETA=0:03:39
[02/09 21:19:07] d2.evaluation.evaluator INFO: Inference done 3193/5000. 0.0747 s / img. ETA=0:03:35
[02/09 21:19:12] d2.evaluation.evaluator INFO: Inference done 3227/5000. 0.0749 s / img. ETA=0:03:32
[02/09 21:19:18] d2.evaluation.evaluator INFO: Inference done 3266/5000. 0.0750 s / img. ETA=0:03:28
[02/09 21:19:23] d2.evaluation.evaluator INFO: Inference done 3303/5000. 0.0752 s / img. ETA=0:03:23
[02/09 21:19:28] d2.evaluation.evaluator INFO: Inference done 3341/5000. 0.0754 s / img. ETA=0:03:19
[02/09 21:19:33] d2.evaluation.evaluator INFO: Inference done 3372/5000. 0.0756 s / img. ETA=0:03:16
[02/09 21:19:38] d2.evaluation.evaluator INFO: Inference done 3415/5000. 0.0757 s / img. ETA=0:03:11
[02/09 21:19:43] d2.evaluation.evaluator INFO: Inference done 3448/5000. 0.0758 s / img. ETA=0:03:07
[02/09 21:19:48] d2.evaluation.evaluator INFO: Inference done 3490/5000. 0.0760 s / img. ETA=0:03:02
[02/09 21:19:53] d2.evaluation.evaluator INFO: Inference done 3525/5000. 0.0762 s / img. ETA=0:02:58
[02/09 21:19:58] d2.evaluation.evaluator INFO: Inference done 3563/5000. 0.0764 s / img. ETA=0:02:54
[02/09 21:20:03] d2.evaluation.evaluator INFO: Inference done 3599/5000. 0.0765 s / img. ETA=0:02:50
[02/09 21:20:08] d2.evaluation.evaluator INFO: Inference done 3637/5000. 0.0767 s / img. ETA=0:02:45
[02/09 21:20:13] d2.evaluation.evaluator INFO: Inference done 3675/5000. 0.0768 s / img. ETA=0:02:41
[02/09 21:20:18] d2.evaluation.evaluator INFO: Inference done 3712/5000. 0.0770 s / img. ETA=0:02:37
[02/09 21:20:24] d2.evaluation.evaluator INFO: Inference done 3750/5000. 0.0771 s / img. ETA=0:02:32
[02/09 21:20:29] d2.evaluation.evaluator INFO: Inference done 3779/5000. 0.0773 s / img. ETA=0:02:29
[02/09 21:20:34] d2.evaluation.evaluator INFO: Inference done 3815/5000. 0.0774 s / img. ETA=0:02:25
[02/09 21:20:39] d2.evaluation.evaluator INFO: Inference done 3854/5000. 0.0776 s / img. ETA=0:02:20
[02/09 21:20:44] d2.evaluation.evaluator INFO: Inference done 3892/5000. 0.0777 s / img. ETA=0:02:16
[02/09 21:20:49] d2.evaluation.evaluator INFO: Inference done 3929/5000. 0.0779 s / img. ETA=0:02:11
[02/09 21:20:54] d2.evaluation.evaluator INFO: Inference done 3966/5000. 0.0780 s / img. ETA=0:02:07
[02/09 21:20:59] d2.evaluation.evaluator INFO: Inference done 4004/5000. 0.0782 s / img. ETA=0:02:02
[02/09 21:21:04] d2.evaluation.evaluator INFO: Inference done 4037/5000. 0.0783 s / img. ETA=0:01:58
[02/09 21:21:09] d2.evaluation.evaluator INFO: Inference done 4071/5000. 0.0784 s / img. ETA=0:01:54
[02/09 21:21:14] d2.evaluation.evaluator INFO: Inference done 4107/5000. 0.0786 s / img. ETA=0:01:50
[02/09 21:21:19] d2.evaluation.evaluator INFO: Inference done 4148/5000. 0.0787 s / img. ETA=0:01:45
[02/09 21:21:24] d2.evaluation.evaluator INFO: Inference done 4179/5000. 0.0788 s / img. ETA=0:01:41
[02/09 21:21:29] d2.evaluation.evaluator INFO: Inference done 4219/5000. 0.0789 s / img. ETA=0:01:36
[02/09 21:21:34] d2.evaluation.evaluator INFO: Inference done 4256/5000. 0.0789 s / img. ETA=0:01:32
[02/09 21:21:40] d2.evaluation.evaluator INFO: Inference done 4291/5000. 0.0790 s / img. ETA=0:01:28
[02/09 21:21:45] d2.evaluation.evaluator INFO: Inference done 4331/5000. 0.0791 s / img. ETA=0:01:23
[02/09 21:21:50] d2.evaluation.evaluator INFO: Inference done 4372/5000. 0.0793 s / img. ETA=0:01:18
[02/09 21:21:55] d2.evaluation.evaluator INFO: Inference done 4409/5000. 0.0794 s / img. ETA=0:01:13
[02/09 21:22:00] d2.evaluation.evaluator INFO: Inference done 4449/5000. 0.0794 s / img. ETA=0:01:08
[02/09 21:22:05] d2.evaluation.evaluator INFO: Inference done 4487/5000. 0.0796 s / img. ETA=0:01:03
[02/09 21:22:10] d2.evaluation.evaluator INFO: Inference done 4524/5000. 0.0797 s / img. ETA=0:00:59
[02/09 21:22:15] d2.evaluation.evaluator INFO: Inference done 4562/5000. 0.0798 s / img. ETA=0:00:54
[02/09 21:22:20] d2.evaluation.evaluator INFO: Inference done 4598/5000. 0.0799 s / img. ETA=0:00:50
[02/09 21:22:25] d2.evaluation.evaluator INFO: Inference done 4637/5000. 0.0800 s / img. ETA=0:00:45
[02/09 21:22:31] d2.evaluation.evaluator INFO: Inference done 4671/5000. 0.0801 s / img. ETA=0:00:41
[02/09 21:22:36] d2.evaluation.evaluator INFO: Inference done 4708/5000. 0.0802 s / img. ETA=0:00:36
[02/09 21:22:41] d2.evaluation.evaluator INFO: Inference done 4746/5000. 0.0803 s / img. ETA=0:00:31
[02/09 21:22:46] d2.evaluation.evaluator INFO: Inference done 4786/5000. 0.0804 s / img. ETA=0:00:26
[02/09 21:22:51] d2.evaluation.evaluator INFO: Inference done 4821/5000. 0.0805 s / img. ETA=0:00:22
[02/09 21:22:56] d2.evaluation.evaluator INFO: Inference done 4860/5000. 0.0805 s / img. ETA=0:00:17
[02/09 21:23:01] d2.evaluation.evaluator INFO: Inference done 4899/5000. 0.0807 s / img. ETA=0:00:12
[02/09 21:23:06] d2.evaluation.evaluator INFO: Inference done 4934/5000. 0.0807 s / img. ETA=0:00:08
[02/09 21:23:11] d2.evaluation.evaluator INFO: Inference done 4975/5000. 0.0808 s / img. ETA=0:00:03
[02/09 21:23:15] d2.evaluation.evaluator INFO: Total inference time: 0:10:28.593784 (0.125845 s / img per device, on 1 devices)
[02/09 21:23:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:43 (0.080838 s / img per device, on 1 devices)
[02/09 21:23:16] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/09 21:23:16] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/09 21:23:17] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[02/09 21:23:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.983 | 61.531 | 44.915 | 24.867 | 43.873 | 53.332 |
[02/09 21:23:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 55.298 | bicycle      | 30.191 | car            | 45.319 |
| motorcycle    | 42.431 | airplane     | 63.266 | bus            | 64.268 |
| train         | 62.870 | truck        | 35.587 | boat           | 26.851 |
| traffic light | 27.773 | fire hydrant | 66.343 | stop sign      | 67.090 |
| parking meter | 45.529 | bench        | 24.565 | bird           | 36.061 |
| cat           | 65.330 | dog          | 58.595 | horse          | 57.380 |
| sheep         | 50.692 | cow          | 53.743 | elephant       | 59.738 |
| bear          | 70.151 | zebra        | 65.603 | giraffe        | 65.381 |
| backpack      | 17.059 | umbrella     | 38.063 | handbag        | 15.099 |
| tie           | 33.637 | suitcase     | 37.302 | frisbee        | 64.712 |
| skis          | 24.532 | snowboard    | 34.820 | sports ball    | 47.006 |
| kite          | 41.695 | baseball bat | 28.480 | baseball glove | 35.169 |
| skateboard    | 50.463 | surfboard    | 36.813 | tennis racket  | 46.433 |
| bottle        | 39.662 | wine glass   | 35.924 | cup            | 41.291 |
| fork          | 33.533 | knife        | 18.537 | spoon          | 17.758 |
| bowl          | 42.382 | banana       | 23.846 | apple          | 21.321 |
| sandwich      | 34.833 | orange       | 30.510 | broccoli       | 22.423 |
| carrot        | 21.232 | hot dog      | 33.351 | pizza          | 50.907 |
| donut         | 44.416 | cake         | 34.571 | chair          | 27.508 |
| couch         | 42.475 | potted plant | 26.177 | bed            | 41.545 |
| dining table  | 27.836 | toilet       | 58.175 | tv             | 55.274 |
| laptop        | 59.256 | mouse        | 64.148 | remote         | 30.946 |
| keyboard      | 51.726 | cell phone   | 35.781 | microwave      | 54.767 |
| oven          | 33.342 | toaster      | 42.398 | sink           | 37.693 |
| refrigerator  | 54.862 | book         | 14.838 | clock          | 49.665 |
| vase          | 37.949 | scissors     | 26.213 | teddy bear     | 44.923 |
| hair drier    | 1.074  | toothbrush   | 22.270 |                |        |
[02/09 21:23:42] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.169 | 58.598 | 39.878 | 18.633 | 39.492 | 53.298 |
[02/09 21:23:42] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 47.659 | bicycle      | 17.969 | car            | 41.815 |
| motorcycle    | 32.986 | airplane     | 49.252 | bus            | 63.667 |
| train         | 61.038 | truck        | 35.068 | boat           | 23.022 |
| traffic light | 26.765 | fire hydrant | 62.378 | stop sign      | 66.174 |
| parking meter | 45.015 | bench        | 17.275 | bird           | 30.338 |
| cat           | 66.854 | dog          | 57.179 | horse          | 41.555 |
| sheep         | 43.681 | cow          | 46.896 | elephant       | 55.802 |
| bear          | 69.355 | zebra        | 56.278 | giraffe        | 51.522 |
| backpack      | 16.440 | umbrella     | 44.650 | handbag        | 14.933 |
| tie           | 31.189 | suitcase     | 39.446 | frisbee        | 62.388 |
| skis          | 3.222  | snowboard    | 21.955 | sports ball    | 46.843 |
| kite          | 30.874 | baseball bat | 24.689 | baseball glove | 38.559 |
| skateboard    | 31.492 | surfboard    | 31.171 | tennis racket  | 53.682 |
| bottle        | 38.238 | wine glass   | 30.948 | cup            | 41.307 |
| fork          | 15.283 | knife        | 12.811 | spoon          | 12.155 |
| bowl          | 40.012 | banana       | 19.467 | apple          | 20.167 |
| sandwich      | 36.739 | orange       | 30.311 | broccoli       | 21.661 |
| carrot        | 18.588 | hot dog      | 27.428 | pizza          | 50.275 |
| donut         | 45.267 | cake         | 35.038 | chair          | 18.140 |
| couch         | 36.135 | potted plant | 22.723 | bed            | 32.042 |
| dining table  | 16.106 | toilet       | 57.366 | tv             | 57.325 |
| laptop        | 59.190 | mouse        | 64.251 | remote         | 28.451 |
| keyboard      | 50.812 | cell phone   | 34.009 | microwave      | 55.995 |
| oven          | 31.137 | toaster      | 43.311 | sink           | 35.765 |
| refrigerator  | 57.000 | book         | 10.240 | clock          | 50.323 |
| vase          | 36.551 | scissors     | 20.594 | teddy bear     | 43.648 |
| hair drier    | 0.636  | toothbrush   | 14.988 |                |        |
[02/09 21:23:43] d2.evaluation.f1score_evaluator INFO: Preparing results for COCO format ...
[02/09 21:23:43] d2.evaluation.f1score_evaluator INFO: Evaluating predictions ...
[02/09 21:24:22] d2.evaluation.f1score_evaluator INFO: Evaluation results for F1-score: 
|  F1_all  |  F1_0.5  |  F1_0.75  |  F1_small  |  F1_medium  |  F1_large  |
|:--------:|:--------:|:---------:|:----------:|:-----------:|:----------:|
|  0.384   |  0.542   |   0.421   |   0.231    |    0.431    |   0.530    |
[02/09 21:24:23] d2.evaluation.tpmqscore_evaluator INFO: Preparing results for COCO format ...
[02/09 21:24:23] d2.evaluation.tpmqscore_evaluator INFO: Evaluating predictions ...
[02/09 21:32:02] d2.evaluation.tpmqscore_evaluator INFO: Evaluation results for TPMQ-score: 
|  TPMQ_small  |  TPMQ_medium  |  TPMQ_large  |  TPMQ_all  |
|:------------:|:-------------:|:------------:|:----------:|
|    0.751     |     0.531     |    0.302     |   0.496    |
[02/09 21:32:04] d2.evaluation.lrp_evaluator INFO: Preparing results for COCO format ...
[02/09 21:32:04] d2.evaluation.lrp_evaluator INFO: Saving results to ./output/inference/coco_instances_results.json
[02/09 21:32:05] d2.evaluation.lrp_evaluator INFO: Evaluating predictions ...
[02/09 21:33:23] d2.evaluation.lrp_evaluator INFO: Evaluation results for LRP-segm: 
|  lrp   |  lrp_loc  |  lrp_fp  |  lrp_fn  |
|:------:|:---------:|:--------:|:--------:|
| 88.412 |  20.572   |  80.323  |  25.278  |
[02/09 21:33:24] d2.engine.defaults INFO: Evaluation results for coco_2017_val in csv format:
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: 40.9835,61.5309,44.9146,24.8667,43.8730,53.3317
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: Task: segm
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: 37.1689,58.5980,39.8783,18.6332,39.4916,53.2981
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: Task: f1-segm
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: F1_all,F1_0.5,F1_0.75,F1_small,F1_medium,F1_large
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: 0.3841,0.5422,0.4215,0.2310,0.4313,0.5296
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: Task: tpmq-segm
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: TPMQ_small,TPMQ_medium,TPMQ_large,TPMQ_all
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: 0.7510,0.5309,0.3018,0.4962
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: Task: lrp-segm
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: lrp,lrp_loc,lrp_fp,lrp_fn
[02/09 21:33:24] d2.evaluation.testing INFO: copypaste: 88.4115,20.5717,80.3235,25.2780
[02/09 21:34:59] detectron2 INFO: Rank of current process: 0. World size: 1
[02/09 21:34:59] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.1.3 @/root/code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  7.2.0
torchvision             0.7.0+cu101 @/root/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.5.post20210624
cv2                     4.5.2
----------------------  --------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[02/09 21:34:59] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/root/data/pretrained_models/mask_rcnn_r101_fpn.pkl'], resume=False)
[02/09 21:34:59] detectron2 INFO: Contents of args.config_file=configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-101.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 101
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/09 21:34:59] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('coco_2017_val',)
  TRAIN: ('coco_2017_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 101
    INIT_DOWNSAMPLE: True
    INIT_MAXPOOL: True
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /root/data/pretrained_models/mask_rcnn_r101_fpn.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  BASE_LR: 0.02
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (210000, 250000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[02/09 21:34:59] detectron2 INFO: Full config saved to ./output/config.yaml
[02/09 21:34:59] d2.utils.env INFO: Using a generated random seed 59987973
[02/09 21:35:02] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[02/09 21:35:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/data/pretrained_models/mask_rcnn_r101_fpn.pkl ...
[02/09 21:35:04] fvcore.common.checkpoint INFO: Reading a file from 'Detectron2 Model Zoo'
[02/09 21:35:05] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from /root/data/mainData/coco/annotations/instances_val2017.json
[02/09 21:35:05] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[02/09 21:35:05] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[02/09 21:35:05] d2.data.common INFO: Serialized dataset takes 19.15 MiB
[02/09 21:35:05] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/09 21:35:07] d2.evaluation.evaluator INFO: Start inference on 5000 images
[02/09 21:35:09] d2.evaluation.evaluator INFO: Inference done 11/5000. 0.0629 s / img. ETA=0:08:12
[02/09 21:35:14] d2.evaluation.evaluator INFO: Inference done 61/5000. 0.0644 s / img. ETA=0:08:17
[02/09 21:35:19] d2.evaluation.evaluator INFO: Inference done 110/5000. 0.0636 s / img. ETA=0:08:15
[02/09 21:35:24] d2.evaluation.evaluator INFO: Inference done 152/5000. 0.0642 s / img. ETA=0:08:37
[02/09 21:35:29] d2.evaluation.evaluator INFO: Inference done 201/5000. 0.0641 s / img. ETA=0:08:26
[02/09 21:35:34] d2.evaluation.evaluator INFO: Inference done 252/5000. 0.0641 s / img. ETA=0:08:16
[02/09 21:35:39] d2.evaluation.evaluator INFO: Inference done 300/5000. 0.0641 s / img. ETA=0:08:12
[02/09 21:35:44] d2.evaluation.evaluator INFO: Inference done 345/5000. 0.0643 s / img. ETA=0:08:12
[02/09 21:35:49] d2.evaluation.evaluator INFO: Inference done 398/5000. 0.0642 s / img. ETA=0:07:59
[02/09 21:35:54] d2.evaluation.evaluator INFO: Inference done 450/5000. 0.0641 s / img. ETA=0:07:50
[02/09 21:35:59] d2.evaluation.evaluator INFO: Inference done 499/5000. 0.0642 s / img. ETA=0:07:45
[02/09 21:36:04] d2.evaluation.evaluator INFO: Inference done 544/5000. 0.0642 s / img. ETA=0:07:43
[02/09 21:36:09] d2.evaluation.evaluator INFO: Inference done 591/5000. 0.0642 s / img. ETA=0:07:39
[02/09 21:36:14] d2.evaluation.evaluator INFO: Inference done 638/5000. 0.0643 s / img. ETA=0:07:36
[02/09 21:36:20] d2.evaluation.evaluator INFO: Inference done 681/5000. 0.0643 s / img. ETA=0:07:36
[02/09 21:36:25] d2.evaluation.evaluator INFO: Inference done 728/5000. 0.0643 s / img. ETA=0:07:31
[02/09 21:36:30] d2.evaluation.evaluator INFO: Inference done 780/5000. 0.0643 s / img. ETA=0:07:23
[02/09 21:36:35] d2.evaluation.evaluator INFO: Inference done 830/5000. 0.0643 s / img. ETA=0:07:17
[02/09 21:36:40] d2.evaluation.evaluator INFO: Inference done 880/5000. 0.0643 s / img. ETA=0:07:11
[02/09 21:36:45] d2.evaluation.evaluator INFO: Inference done 929/5000. 0.0643 s / img. ETA=0:07:05
[02/09 21:36:50] d2.evaluation.evaluator INFO: Inference done 980/5000. 0.0643 s / img. ETA=0:06:59
[02/09 21:36:55] d2.evaluation.evaluator INFO: Inference done 1031/5000. 0.0643 s / img. ETA=0:06:52
[02/09 21:37:00] d2.evaluation.evaluator INFO: Inference done 1078/5000. 0.0643 s / img. ETA=0:06:48
[02/09 21:37:05] d2.evaluation.evaluator INFO: Inference done 1129/5000. 0.0643 s / img. ETA=0:06:42
[02/09 21:37:10] d2.evaluation.evaluator INFO: Inference done 1174/5000. 0.0644 s / img. ETA=0:06:38
[02/09 21:37:15] d2.evaluation.evaluator INFO: Inference done 1219/5000. 0.0644 s / img. ETA=0:06:35
[02/09 21:37:20] d2.evaluation.evaluator INFO: Inference done 1258/5000. 0.0644 s / img. ETA=0:06:33
[02/09 21:37:25] d2.evaluation.evaluator INFO: Inference done 1310/5000. 0.0644 s / img. ETA=0:06:27
[02/09 21:37:30] d2.evaluation.evaluator INFO: Inference done 1356/5000. 0.0644 s / img. ETA=0:06:23
[02/09 21:37:35] d2.evaluation.evaluator INFO: Inference done 1407/5000. 0.0644 s / img. ETA=0:06:16
[02/09 21:37:40] d2.evaluation.evaluator INFO: Inference done 1456/5000. 0.0644 s / img. ETA=0:06:11
[02/09 21:37:45] d2.evaluation.evaluator INFO: Inference done 1503/5000. 0.0643 s / img. ETA=0:06:06
[02/09 21:37:50] d2.evaluation.evaluator INFO: Inference done 1550/5000. 0.0643 s / img. ETA=0:06:02
[02/09 21:37:56] d2.evaluation.evaluator INFO: Inference done 1595/5000. 0.0644 s / img. ETA=0:05:58
[02/09 21:38:01] d2.evaluation.evaluator INFO: Inference done 1645/5000. 0.0644 s / img. ETA=0:05:52
[02/09 21:38:06] d2.evaluation.evaluator INFO: Inference done 1694/5000. 0.0644 s / img. ETA=0:05:47
[02/09 21:38:11] d2.evaluation.evaluator INFO: Inference done 1743/5000. 0.0644 s / img. ETA=0:05:42
[02/09 21:38:16] d2.evaluation.evaluator INFO: Inference done 1795/5000. 0.0643 s / img. ETA=0:05:35
[02/09 21:38:21] d2.evaluation.evaluator INFO: Inference done 1843/5000. 0.0643 s / img. ETA=0:05:30
[02/09 21:38:26] d2.evaluation.evaluator INFO: Inference done 1891/5000. 0.0643 s / img. ETA=0:05:25
[02/09 21:38:31] d2.evaluation.evaluator INFO: Inference done 1944/5000. 0.0643 s / img. ETA=0:05:19
[02/09 21:38:36] d2.evaluation.evaluator INFO: Inference done 1990/5000. 0.0643 s / img. ETA=0:05:14
[02/09 21:38:41] d2.evaluation.evaluator INFO: Inference done 2033/5000. 0.0643 s / img. ETA=0:05:11
[02/09 21:38:46] d2.evaluation.evaluator INFO: Inference done 2084/5000. 0.0643 s / img. ETA=0:05:05
[02/09 21:38:51] d2.evaluation.evaluator INFO: Inference done 2134/5000. 0.0643 s / img. ETA=0:04:59
[02/09 21:38:56] d2.evaluation.evaluator INFO: Inference done 2183/5000. 0.0643 s / img. ETA=0:04:54
[02/09 21:39:01] d2.evaluation.evaluator INFO: Inference done 2231/5000. 0.0643 s / img. ETA=0:04:49
[02/09 21:39:06] d2.evaluation.evaluator INFO: Inference done 2281/5000. 0.0643 s / img. ETA=0:04:44
[02/09 21:39:11] d2.evaluation.evaluator INFO: Inference done 2334/5000. 0.0643 s / img. ETA=0:04:38
[02/09 21:39:16] d2.evaluation.evaluator INFO: Inference done 2385/5000. 0.0643 s / img. ETA=0:04:32
[02/09 21:39:21] d2.evaluation.evaluator INFO: Inference done 2430/5000. 0.0643 s / img. ETA=0:04:28
[02/09 21:39:26] d2.evaluation.evaluator INFO: Inference done 2479/5000. 0.0643 s / img. ETA=0:04:23
[02/09 21:39:31] d2.evaluation.evaluator INFO: Inference done 2526/5000. 0.0643 s / img. ETA=0:04:18
[02/09 21:39:37] d2.evaluation.evaluator INFO: Inference done 2572/5000. 0.0643 s / img. ETA=0:04:13
[02/09 21:39:42] d2.evaluation.evaluator INFO: Inference done 2617/5000. 0.0643 s / img. ETA=0:04:09
[02/09 21:39:47] d2.evaluation.evaluator INFO: Inference done 2666/5000. 0.0644 s / img. ETA=0:04:04
[02/09 21:39:52] d2.evaluation.evaluator INFO: Inference done 2720/5000. 0.0644 s / img. ETA=0:03:58
[02/09 21:39:57] d2.evaluation.evaluator INFO: Inference done 2768/5000. 0.0643 s / img. ETA=0:03:53
[02/09 21:40:02] d2.evaluation.evaluator INFO: Inference done 2816/5000. 0.0644 s / img. ETA=0:03:48
[02/09 21:40:07] d2.evaluation.evaluator INFO: Inference done 2865/5000. 0.0644 s / img. ETA=0:03:42
[02/09 21:40:12] d2.evaluation.evaluator INFO: Inference done 2911/5000. 0.0644 s / img. ETA=0:03:38
[02/09 21:40:17] d2.evaluation.evaluator INFO: Inference done 2960/5000. 0.0644 s / img. ETA=0:03:33
[02/09 21:40:22] d2.evaluation.evaluator INFO: Inference done 3003/5000. 0.0644 s / img. ETA=0:03:29
[02/09 21:40:27] d2.evaluation.evaluator INFO: Inference done 3054/5000. 0.0644 s / img. ETA=0:03:23
[02/09 21:40:32] d2.evaluation.evaluator INFO: Inference done 3106/5000. 0.0644 s / img. ETA=0:03:17
[02/09 21:40:37] d2.evaluation.evaluator INFO: Inference done 3154/5000. 0.0644 s / img. ETA=0:03:12
[02/09 21:40:42] d2.evaluation.evaluator INFO: Inference done 3203/5000. 0.0644 s / img. ETA=0:03:07
[02/09 21:40:47] d2.evaluation.evaluator INFO: Inference done 3248/5000. 0.0644 s / img. ETA=0:03:03
[02/09 21:40:52] d2.evaluation.evaluator INFO: Inference done 3292/5000. 0.0644 s / img. ETA=0:02:58
[02/09 21:40:58] d2.evaluation.evaluator INFO: Inference done 3341/5000. 0.0644 s / img. ETA=0:02:53
[02/09 21:41:03] d2.evaluation.evaluator INFO: Inference done 3387/5000. 0.0644 s / img. ETA=0:02:49
[02/09 21:41:08] d2.evaluation.evaluator INFO: Inference done 3435/5000. 0.0644 s / img. ETA=0:02:44
[02/09 21:41:13] d2.evaluation.evaluator INFO: Inference done 3484/5000. 0.0644 s / img. ETA=0:02:38
[02/09 21:41:18] d2.evaluation.evaluator INFO: Inference done 3534/5000. 0.0644 s / img. ETA=0:02:33
[02/09 21:41:23] d2.evaluation.evaluator INFO: Inference done 3581/5000. 0.0645 s / img. ETA=0:02:28
[02/09 21:41:28] d2.evaluation.evaluator INFO: Inference done 3629/5000. 0.0645 s / img. ETA=0:02:23
[02/09 21:41:33] d2.evaluation.evaluator INFO: Inference done 3679/5000. 0.0645 s / img. ETA=0:02:18
[02/09 21:41:38] d2.evaluation.evaluator INFO: Inference done 3729/5000. 0.0645 s / img. ETA=0:02:13
[02/09 21:41:43] d2.evaluation.evaluator INFO: Inference done 3776/5000. 0.0645 s / img. ETA=0:02:08
[02/09 21:41:48] d2.evaluation.evaluator INFO: Inference done 3823/5000. 0.0645 s / img. ETA=0:02:03
[02/09 21:41:53] d2.evaluation.evaluator INFO: Inference done 3874/5000. 0.0645 s / img. ETA=0:01:57
[02/09 21:41:58] d2.evaluation.evaluator INFO: Inference done 3926/5000. 0.0645 s / img. ETA=0:01:52
[02/09 21:42:03] d2.evaluation.evaluator INFO: Inference done 3975/5000. 0.0645 s / img. ETA=0:01:47
[02/09 21:42:08] d2.evaluation.evaluator INFO: Inference done 4023/5000. 0.0645 s / img. ETA=0:01:42
[02/09 21:42:14] d2.evaluation.evaluator INFO: Inference done 4070/5000. 0.0645 s / img. ETA=0:01:37
[02/09 21:42:19] d2.evaluation.evaluator INFO: Inference done 4118/5000. 0.0645 s / img. ETA=0:01:32
[02/09 21:42:24] d2.evaluation.evaluator INFO: Inference done 4159/5000. 0.0645 s / img. ETA=0:01:28
[02/09 21:42:29] d2.evaluation.evaluator INFO: Inference done 4203/5000. 0.0645 s / img. ETA=0:01:23
[02/09 21:42:34] d2.evaluation.evaluator INFO: Inference done 4251/5000. 0.0645 s / img. ETA=0:01:18
[02/09 21:42:39] d2.evaluation.evaluator INFO: Inference done 4297/5000. 0.0645 s / img. ETA=0:01:13
[02/09 21:42:44] d2.evaluation.evaluator INFO: Inference done 4352/5000. 0.0645 s / img. ETA=0:01:07
[02/09 21:42:49] d2.evaluation.evaluator INFO: Inference done 4403/5000. 0.0645 s / img. ETA=0:01:02
[02/09 21:42:54] d2.evaluation.evaluator INFO: Inference done 4452/5000. 0.0645 s / img. ETA=0:00:57
[02/09 21:42:59] d2.evaluation.evaluator INFO: Inference done 4500/5000. 0.0645 s / img. ETA=0:00:52
[02/09 21:43:04] d2.evaluation.evaluator INFO: Inference done 4552/5000. 0.0645 s / img. ETA=0:00:46
[02/09 21:43:09] d2.evaluation.evaluator INFO: Inference done 4598/5000. 0.0645 s / img. ETA=0:00:42
[02/09 21:43:14] d2.evaluation.evaluator INFO: Inference done 4649/5000. 0.0645 s / img. ETA=0:00:36
[02/09 21:43:19] d2.evaluation.evaluator INFO: Inference done 4697/5000. 0.0645 s / img. ETA=0:00:31
[02/09 21:43:25] d2.evaluation.evaluator INFO: Inference done 4746/5000. 0.0645 s / img. ETA=0:00:26
[02/09 21:43:30] d2.evaluation.evaluator INFO: Inference done 4797/5000. 0.0645 s / img. ETA=0:00:21
[02/09 21:43:35] d2.evaluation.evaluator INFO: Inference done 4847/5000. 0.0645 s / img. ETA=0:00:16
[02/09 21:43:40] d2.evaluation.evaluator INFO: Inference done 4898/5000. 0.0645 s / img. ETA=0:00:10
[02/09 21:43:45] d2.evaluation.evaluator INFO: Inference done 4942/5000. 0.0645 s / img. ETA=0:00:06
[02/09 21:43:50] d2.evaluation.evaluator INFO: Inference done 4992/5000. 0.0645 s / img. ETA=0:00:00
[02/09 21:43:51] d2.evaluation.evaluator INFO: Total inference time: 0:08:42.583538 (0.104621 s / img per device, on 1 devices)
[02/09 21:43:51] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:05:22 (0.064509 s / img per device, on 1 devices)
[02/09 21:43:52] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/09 21:43:52] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/09 21:43:53] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[02/09 21:44:01] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.928 | 63.323 | 46.834 | 26.396 | 46.595 | 56.127 |
[02/09 21:44:01] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 56.564 | bicycle      | 33.320 | car            | 46.299 |
| motorcycle    | 45.460 | airplane     | 64.943 | bus            | 67.283 |
| train         | 63.870 | truck        | 37.436 | boat           | 30.259 |
| traffic light | 28.938 | fire hydrant | 69.259 | stop sign      | 69.186 |
| parking meter | 47.573 | bench        | 25.150 | bird           | 38.127 |
| cat           | 69.155 | dog          | 62.371 | horse          | 58.714 |
| sheep         | 54.080 | cow          | 56.453 | elephant       | 62.169 |
| bear          | 72.848 | zebra        | 67.389 | giraffe        | 67.861 |
| backpack      | 19.134 | umbrella     | 39.688 | handbag        | 17.461 |
| tie           | 38.011 | suitcase     | 40.343 | frisbee        | 65.476 |
| skis          | 27.408 | snowboard    | 37.717 | sports ball    | 48.816 |
| kite          | 43.435 | baseball bat | 28.747 | baseball glove | 38.689 |
| skateboard    | 55.744 | surfboard    | 38.965 | tennis racket  | 50.825 |
| bottle        | 41.597 | wine glass   | 38.114 | cup            | 44.020 |
| fork          | 38.213 | knife        | 21.140 | spoon          | 20.224 |
| bowl          | 42.897 | banana       | 24.497 | apple          | 21.714 |
| sandwich      | 36.331 | orange       | 31.943 | broccoli       | 23.172 |
| carrot        | 23.027 | hot dog      | 36.191 | pizza          | 52.115 |
| donut         | 46.332 | cake         | 37.851 | chair          | 29.237 |
| couch         | 42.566 | potted plant | 27.836 | bed            | 42.395 |
| dining table  | 29.027 | toilet       | 59.803 | tv             | 57.551 |
| laptop        | 62.153 | mouse        | 63.043 | remote         | 34.054 |
| keyboard      | 51.766 | cell phone   | 37.615 | microwave      | 55.712 |
| oven          | 34.679 | toaster      | 37.318 | sink           | 38.235 |
| refrigerator  | 56.564 | book         | 16.775 | clock          | 52.138 |
| vase          | 39.835 | scissors     | 27.648 | teddy bear     | 46.279 |
| hair drier    | 3.819  | toothbrush   | 23.679 |                |        |
[02/09 21:44:17] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.629 | 60.449 | 41.271 | 19.484 | 41.324 | 55.289 |
[02/09 21:44:17] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 48.656 | bicycle      | 19.881 | car            | 42.382 |
| motorcycle    | 35.045 | airplane     | 51.234 | bus            | 65.135 |
| train         | 62.638 | truck        | 36.306 | boat           | 25.069 |
| traffic light | 27.870 | fire hydrant | 64.924 | stop sign      | 68.890 |
| parking meter | 48.242 | bench        | 18.392 | bird           | 32.358 |
| cat           | 67.826 | dog          | 59.535 | horse          | 41.996 |
| sheep         | 46.230 | cow          | 48.225 | elephant       | 56.882 |
| bear          | 70.021 | zebra        | 58.701 | giraffe        | 51.385 |
| backpack      | 18.037 | umbrella     | 46.775 | handbag        | 16.628 |
| tie           | 35.347 | suitcase     | 42.334 | frisbee        | 64.217 |
| skis          | 4.251  | snowboard    | 21.587 | sports ball    | 48.371 |
| kite          | 31.612 | baseball bat | 25.290 | baseball glove | 41.278 |
| skateboard    | 33.579 | surfboard    | 31.947 | tennis racket  | 56.314 |
| bottle        | 39.788 | wine glass   | 33.805 | cup            | 43.778 |
| fork          | 18.271 | knife        | 13.514 | spoon          | 13.922 |
| bowl          | 39.950 | banana       | 19.389 | apple          | 20.794 |
| sandwich      | 37.969 | orange       | 31.768 | broccoli       | 22.995 |
| carrot        | 19.378 | hot dog      | 30.518 | pizza          | 50.659 |
| donut         | 46.410 | cake         | 37.695 | chair          | 19.690 |
| couch         | 36.093 | potted plant | 23.250 | bed            | 33.749 |
| dining table  | 17.044 | toilet       | 59.537 | tv             | 60.378 |
| laptop        | 60.789 | mouse        | 63.925 | remote         | 32.339 |
| keyboard      | 50.498 | cell phone   | 36.643 | microwave      | 56.980 |
| oven          | 32.181 | toaster      | 40.386 | sink           | 36.194 |
| refrigerator  | 58.806 | book         | 10.848 | clock          | 51.760 |
| vase          | 38.709 | scissors     | 22.377 | teddy bear     | 44.713 |
| hair drier    | 2.207  | toothbrush   | 15.221 |                |        |
[02/09 21:44:17] d2.evaluation.f1score_evaluator INFO: Preparing results for COCO format ...
[02/09 21:44:17] d2.evaluation.f1score_evaluator INFO: Evaluating predictions ...
[02/09 21:44:54] d2.evaluation.f1score_evaluator INFO: Evaluation results for F1-score: 
|  F1_all  |  F1_0.5  |  F1_0.75  |  F1_small  |  F1_medium  |  F1_large  |
|:--------:|:--------:|:---------:|:----------:|:-----------:|:----------:|
|  0.417   |  0.583   |   0.458   |   0.255    |    0.454    |   0.571    |
[02/09 21:44:55] d2.evaluation.tpmqscore_evaluator INFO: Preparing results for COCO format ...
[02/09 21:44:55] d2.evaluation.tpmqscore_evaluator INFO: Evaluating predictions ...
[02/09 21:53:00] d2.evaluation.tpmqscore_evaluator INFO: Evaluation results for TPMQ-score: 
|  TPMQ_small  |  TPMQ_medium  |  TPMQ_large  |  TPMQ_all  |
|:------------:|:-------------:|:------------:|:----------:|
|    0.754     |     0.538     |    0.312     |   0.504    |
[02/09 21:53:01] d2.evaluation.lrp_evaluator INFO: Preparing results for COCO format ...
[02/09 21:53:01] d2.evaluation.lrp_evaluator INFO: Saving results to ./output/inference/coco_instances_results.json
[02/09 21:53:02] d2.evaluation.lrp_evaluator INFO: Evaluating predictions ...
[02/09 21:54:17] d2.evaluation.lrp_evaluator INFO: Evaluation results for LRP-segm: 
|  lrp   |  lrp_loc  |  lrp_fp  |  lrp_fn  |
|:------:|:---------:|:--------:|:--------:|
| 86.626 |  19.961   |  77.480  |  24.299  |
[02/09 21:54:17] d2.engine.defaults INFO: Evaluation results for coco_2017_val in csv format:
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: 42.9284,63.3233,46.8341,26.3962,46.5951,56.1266
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: Task: segm
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: 38.6289,60.4491,41.2707,19.4837,41.3244,55.2890
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: Task: f1-segm
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: F1_all,F1_0.5,F1_0.75,F1_small,F1_medium,F1_large
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: 0.4174,0.5832,0.4577,0.2546,0.4537,0.5710
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: Task: tpmq-segm
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: TPMQ_small,TPMQ_medium,TPMQ_large,TPMQ_all
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: 0.7545,0.5377,0.3123,0.5042
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: Task: lrp-segm
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: lrp,lrp_loc,lrp_fp,lrp_fn
[02/09 21:54:17] d2.evaluation.testing INFO: copypaste: 86.6259,19.9612,77.4795,24.2989
